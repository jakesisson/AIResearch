#!/usr/bin/env python3
"""
Advanced LangGraph Features with Aigie Monitoring

This example demonstrates the most advanced features of modern LangGraph with comprehensive aigie monitoring:

üöÄ Advanced Features:
- Human-in-the-Loop with approval checkpoints and interrupt()
- Advanced checkpointing with SqliteSaver and thread management
- Command objects for dynamic flow control
- Custom state schemas with proper typing
- Advanced streaming patterns with event filtering
- Multi-agent coordination with sub-graphs
- Error recovery with conditional routing
- Real-time monitoring of all execution paths

üîç Aigie Integration:
- Monitors all modern LangGraph components
- Tracks human interactions and approvals
- Monitors checkpoint operations and state persistence
- Analyzes streaming events in real-time
- Provides AI-powered error remediation
- Tracks multi-agent coordination patterns

Requirements:
- LangGraph latest version with all features
- SQLite for advanced checkpointing
- GEMINI_API_KEY for model and enhanced error analysis
- langchain-google-genai package
"""

import os
import sys
import asyncio
import json
import sqlite3
import logging
import time
from typing import Dict, Any, List, Optional, Literal, TypedDict, Annotated
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

# Add parent directory for aigie imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from aigie.core.error_detector import ErrorDetector, AsyncErrorDetector
from aigie.interceptors.langchain import LangChainInterceptor
from aigie.interceptors.langgraph import LangGraphInterceptor
from aigie.reporting.logger import AigieLogger

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ============================================================================
# Advanced State Management with Typing
# ============================================================================

from langchain_core.callbacks import BaseCallbackHandler


class ResearchState(TypedDict):
    """Advanced state schema with proper typing."""
    # Core workflow state
    messages: List[Dict[str, Any]]
    current_step: Literal["planning", "research", "analysis", "review", "completed"]
    
    # Research data
    query: str
    search_results: List[Dict[str, Any]]
    analysis_results: List[Dict[str, Any]]
    
    # Human interaction state
    pending_approval: Optional[str]
    user_feedback: List[str]
    approval_history: List[Dict[str, Any]]
    
    # Multi-agent coordination
    active_agents: List[str]
    agent_outputs: Dict[str, Any]
    coordination_log: List[str]
    
    # Error handling and recovery
    error_count: int
    recovery_attempts: List[str]
    last_error: Optional[str]
    
    # Execution metadata
    execution_id: str
    start_time: datetime
    last_update: datetime

@dataclass
class AdvancedConfig:
    """Configuration for advanced features."""
    # Model settings
    PRIMARY_MODEL: str = "google:gemini-1.5-flash"
    FALLBACK_MODEL: str = "google:gemini-1.5-pro"
    
    # Human-in-the-loop settings
    REQUIRE_HUMAN_APPROVAL: bool = True
    APPROVAL_TIMEOUT_SECONDS: int = 60
    AUTO_APPROVE_LOW_RISK: bool = True
    
    # Checkpointing
    USE_SQLITE_CHECKPOINT: bool = True
    CHECKPOINT_DB_PATH: str = "./checkpoints/advanced_research.db"
    
    # Multi-agent settings
    MAX_PARALLEL_AGENTS: int = 3
    COORDINATION_TIMEOUT: int = 30
    
    # Error handling
    MAX_RECOVERY_ATTEMPTS: int = 3
    AUTO_RECOVERY_ENABLED: bool = True


def get_llm():
    """Create LLM from env: Azure OpenAI if credentials set, else Google Gemini."""
    if os.getenv("AZURE_OPENAI_API_KEY") and os.getenv("AZURE_OPENAI_ENDPOINT"):
        from langchain_openai import AzureChatOpenAI
        deployment = os.getenv("AZURE_OPENAI_API_DEPLOYMENT") or os.getenv("MODEL_ID", "gpt-4.1")
        return AzureChatOpenAI(
            azure_deployment=deployment,
            api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2025-01-01-preview"),
            temperature=0.1,
        )
    from langchain_google_genai import ChatGoogleGenerativeAI
    return ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.1)


# ============================================================================
# Real LLM-Powered Research Tools (for cost-perf comparison with researched)
# ============================================================================

async def advanced_web_search_with_llm(query: str, depth: Literal["basic", "comprehensive"] = "basic", model=None) -> List[Dict[str, Any]]:
    """Real web search using LLM to generate research sources."""
    logger.info(f"üîç LLM-powered web search: {query} (depth: {depth})")
    if not model:
        model = get_llm()
    search_prompt = f"""You are a research assistant. For the query "{query}", generate {depth} research sources.
For each source provide: 1) A realistic academic title 2) A detailed abstract (2-3 sentences) 3) A realistic URL 4) Publication year (2020-2024) 5) Methodology type 6) Key findings.
Return as JSON array with fields: title, abstract, url, year, methodology, key_findings, relevance_score"""
    try:
        response = await model.ainvoke(search_prompt)
        import json
        import re
        content = response.content
        json_match = re.search(r'\[.*\]', content, re.DOTALL)
        if json_match:
            sources_data = json.loads(json_match.group())
        else:
            sources_data = [{"title": f"Research on {query}", "abstract": content[:200], "url": "https://research.com/1", "year": 2023, "methodology": "experimental", "key_findings": "Findings", "relevance_score": 0.9}]
        results = []
        for i, source in enumerate(sources_data):
            results.append({
                "id": f"llm_result_{i}",
                "title": source.get("title", f"Research on {query}"),
                "url": source.get("url", f"https://research.com/paper-{i}"),
                "abstract": source.get("abstract", ""),
                "relevance_score": source.get("relevance_score", 0.85),
                "publication_date": str(source.get("year", 2023)),
                "methodology": source.get("methodology", "experimental"),
                "key_findings": source.get("key_findings", "Findings"),
                "confidence": 0.9
            })
        logger.info(f"‚úÖ LLM generated {len(results)} research sources")
        return results
    except Exception as e:
        logger.error(f"LLM search failed: {e}")
        return [{"id": "fallback", "title": f"Research on {query}", "url": "https://research.com/fallback", "abstract": str(e), "relevance_score": 0.8, "publication_date": "2023", "methodology": "experimental", "key_findings": "Fallback", "confidence": 0.8}]

async def deep_analysis_with_llm(source_data: Dict[str, Any], analysis_type: Literal["statistical", "qualitative", "mixed"] = "mixed", model=None) -> Dict[str, Any]:
    """Real deep analysis using LLM."""
    logger.info(f"üî¨ LLM-powered analysis: {analysis_type} on {source_data.get('title', 'Unknown')}")
    if not model:
        model = get_llm()
    analysis_prompt = f"""You are a research analyst. Perform a {analysis_type} analysis on this source:
Title: {source_data.get('title', 'Unknown')}
Abstract: {source_data.get('abstract', '')}
Key Findings: {source_data.get('key_findings', '')}
Methodology: {source_data.get('methodology', 'Unknown')}
Provide analysis as JSON with fields: findings, metrics, quality_score, recommendations, analysis_summary"""
    try:
        import time
        response = await model.ainvoke(analysis_prompt)
        content = response.content
        import json
        import re
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            analysis_data = json.loads(json_match.group())
        else:
            analysis_data = {"findings": [content[:200]], "metrics": {"confidence": 0.85}, "quality_score": 0.9, "recommendations": [], "analysis_summary": content[:200]}
        analysis_result = {
            "analysis_id": f"llm_analysis_{int(time.time())}",
            "source": source_data.get("title", "Unknown"),
            "methodology": analysis_type,
            "findings": analysis_data.get("findings", ["Analysis completed"]),
            "metrics": analysis_data.get("metrics", {"confidence": 0.85}),
            "quality_score": analysis_data.get("quality_score", 0.9),
            "processing_time": 2.0,
            "recommendations": analysis_data.get("recommendations", []),
            "analysis_summary": analysis_data.get("analysis_summary", "LLM analysis completed"),
            "llm_generated": True
        }
        logger.info(f"‚úÖ LLM analysis complete (quality: {analysis_result['quality_score']:.1%})")
        return analysis_result
    except Exception as e:
        logger.error(f"LLM analysis failed: {e}")
        return {"analysis_id": f"fallback_{int(__import__('time').time())}", "source": source_data.get("title", "Unknown"), "methodology": analysis_type, "findings": ["Fallback"], "metrics": {"confidence": 0.7}, "quality_score": 0.7, "processing_time": 1.0, "recommendations": [], "analysis_summary": "Fallback", "llm_generated": False}

async def synthesis_engine_with_llm(analysis_results: List[Dict[str, Any]], synthesis_mode: str = "comprehensive", model=None) -> Dict[str, Any]:
    """Real synthesis using LLM to combine analyses."""
    logger.info(f"üîÑ LLM-powered synthesis: {len(analysis_results)} analyses (mode: {synthesis_mode})")
    if not model:
        model = get_llm()
    analysis_summaries = "\n".join([f"Analysis {i+1}: Source: {a.get('source')}; Findings: {a.get('findings', [])}; Quality: {a.get('quality_score', 0.8)}" for i, a in enumerate(analysis_results)])
    synthesis_prompt = f"""You are a research synthesis expert. Synthesize these {len(analysis_results)} analyses:\n{analysis_summaries}\nReturn as JSON with fields: unified_findings, confidence_level, consensus_score, key_insights, quality_metrics, synthesis_summary"""
    try:
        import time
        response = await model.ainvoke(synthesis_prompt)
        content = response.content
        import json
        import re
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            synthesis_data = json.loads(json_match.group())
        else:
            synthesis_data = {"unified_findings": ["Synthesis completed"], "confidence_level": 0.9, "consensus_score": 0.85, "key_insights": [], "quality_metrics": {}, "synthesis_summary": content[:200]}
        synthesis = {
            "synthesis_id": f"llm_synthesis_{int(time.time())}",
            "input_analyses": len(analysis_results),
            "mode": synthesis_mode,
            "unified_findings": synthesis_data.get("unified_findings", ["Synthesis completed"]),
            "confidence_level": synthesis_data.get("confidence_level", 0.9),
            "consensus_score": synthesis_data.get("consensus_score", 0.85),
            "key_insights": synthesis_data.get("key_insights", []),
            "quality_metrics": synthesis_data.get("quality_metrics", {}),
            "synthesis_summary": synthesis_data.get("synthesis_summary", "LLM synthesis completed"),
            "llm_generated": True
        }
        logger.info(f"‚úÖ LLM synthesis complete (confidence: {synthesis['confidence_level']:.1%})")
        return synthesis
    except Exception as e:
        logger.error(f"LLM synthesis failed: {e}")
        return {"synthesis_id": f"fallback_{int(__import__('time').time())}", "input_analyses": len(analysis_results), "mode": synthesis_mode, "unified_findings": ["Fallback"], "confidence_level": 0.7, "consensus_score": 0.7, "key_insights": [], "quality_metrics": {}, "synthesis_summary": "Fallback", "llm_generated": False}


# ============================================================================
# Advanced Research Tools with Error Simulation (mocks; kept for compatibility)
# ============================================================================

def advanced_web_search(query: str, depth: Literal["basic", "comprehensive"] = "basic") -> List[Dict[str, Any]]:
    """Advanced web search with depth control and error simulation."""
    logger.info(f"üîç Advanced web search: {query} (depth: {depth})")
    
    # Simulate various error conditions
    import random
    if random.random() < 0.1:
        raise ConnectionError("Network timeout during advanced search")
    if random.random() < 0.05:
        raise ValueError(f"Invalid search query format: {query}")
    
    # Generate results based on depth
    num_results = 3 if depth == "basic" else 10
    results = []
    
    for i in range(num_results):
        results.append({
            "id": f"result_{i}",
            "title": f"Advanced Research Paper: {query} - Study {i+1}",
            "url": f"https://advanced-research.com/paper-{i}",
            "abstract": f"Comprehensive analysis of {query} using advanced methodologies.",
            "relevance_score": random.uniform(0.8, 0.98),
            "publication_date": f"202{random.randint(0, 4)}-{random.randint(1, 12):02d}",
            "citation_count": random.randint(50, 1000),
            "methodology": random.choice(["experimental", "observational", "meta-analysis"]),
            "confidence": random.uniform(0.85, 0.95)
        })
    
    logger.info(f"‚úÖ Found {len(results)} advanced research sources")
    return results

def deep_analysis_tool(source_data: Dict[str, Any], analysis_type: Literal["statistical", "qualitative", "mixed"] = "mixed") -> Dict[str, Any]:
    """Perform deep analysis with multiple methodologies."""
    logger.info(f"üî¨ Deep analysis: {analysis_type} on {source_data.get('title', 'Unknown')}")
    
    # Simulate processing errors
    import random
    if random.random() < 0.15:
        raise RuntimeError("Analysis processing failed - insufficient data quality")
    
    import time
    time.sleep(random.uniform(1.0, 2.5))  # Simulate processing time
    
    # Generate comprehensive analysis
    analysis_result = {
        "analysis_id": f"analysis_{int(time.time())}",
        "source": source_data.get("title", "Unknown Source"),
        "methodology": analysis_type,
        "findings": [
            f"Significant correlation found in {analysis_type} analysis",
            f"Effect size: {random.choice(['small', 'medium', 'large'])}",
            f"Confidence interval: {random.uniform(0.90, 0.99):.2%}",
            f"Statistical power: {random.uniform(0.80, 0.95):.2%}"
        ],
        "metrics": {
            "p_value": random.uniform(0.001, 0.049),
            "effect_size": random.uniform(0.3, 0.8),
            "sample_size": random.randint(200, 2000),
            "power": random.uniform(0.80, 0.95)
        },
        "quality_score": random.uniform(0.85, 0.98),
        "processing_time": random.uniform(1.0, 2.5),
        "recommendations": [
            "Consider expanding sample size for greater generalization",
            "Implement cross-validation for robust findings",
            "Explore additional confounding variables"
        ]
    }
    
    logger.info(f"‚úÖ Deep analysis complete (quality: {analysis_result['quality_score']:.1%})")
    return analysis_result

def synthesis_engine(analysis_results: List[Dict[str, Any]], synthesis_mode: str = "comprehensive") -> Dict[str, Any]:
    """Synthesize multiple analysis results into unified insights."""
    logger.info(f"üîÑ Synthesizing {len(analysis_results)} analyses (mode: {synthesis_mode})")
    
    # Simulate synthesis errors
    import random
    if random.random() < 0.08:
        raise ValueError("Synthesis failed - conflicting analysis methodologies")
    
    import time
    time.sleep(random.uniform(2.0, 3.0))
    
    # Generate synthesis
    synthesis = {
        "synthesis_id": f"synthesis_{int(time.time())}",
        "input_analyses": len(analysis_results),
        "mode": synthesis_mode,
        "unified_findings": [
            "Cross-analysis validation shows consistent patterns",
            f"Meta-analysis effect size: {random.uniform(0.4, 0.7):.3f}",
            f"Heterogeneity I¬≤: {random.uniform(0.2, 0.6):.1%}",
            "Evidence quality: High across multiple studies"
        ],
        "confidence_level": random.uniform(0.90, 0.97),
        "consensus_score": random.uniform(0.85, 0.95),
        "key_insights": [
            "Significant convergence across methodologies",
            "Robust findings with high replication potential",
            "Clinical/practical significance confirmed"
        ],
        "quality_metrics": {
            "internal_validity": random.uniform(0.80, 0.95),
            "external_validity": random.uniform(0.75, 0.90),
            "statistical_power": random.uniform(0.85, 0.98)
        }
    }
    
    logger.info(f"‚úÖ Synthesis complete (confidence: {synthesis['confidence_level']:.1%})")
    return synthesis

# ============================================================================
# Human-in-the-Loop Functions
# ============================================================================

def require_human_approval(action: str, details: Dict[str, Any], risk_level: Literal["low", "medium", "high"]) -> bool:
    """Request human approval for actions based on risk level."""
    if os.environ.get("COST_PERF"):
        return True
    config = AdvancedConfig()
    
    # Auto-approve low-risk actions if configured
    if risk_level == "low" and config.AUTO_APPROVE_LOW_RISK:
        logger.info(f"‚úÖ Auto-approved low-risk action: {action}")
        return True
    
    if not config.REQUIRE_HUMAN_APPROVAL:
        return True
    
    print(f"\nüö® HUMAN APPROVAL REQUIRED")
    print(f"Action: {action}")
    print(f"Risk Level: {risk_level.upper()}")
    print(f"Details: {details}")
    print(f"Approve? (y/n/details): ", end="")
    
    try:
        import select
        import sys
        
        # Simple approval mechanism (in production, use proper UI)
        response = input().strip().lower()
        
        if response in ['y', 'yes']:
            logger.info(f"‚úÖ Human approved: {action}")
            return True
        elif response in ['n', 'no']:
            logger.info(f"‚ùå Human denied: {action}")
            return False
        else:
            print("Please respond with 'y' (yes) or 'n' (no)")
            return require_human_approval(action, details, risk_level)
            
    except KeyboardInterrupt:
        logger.info("‚ùå Human approval interrupted")
        return False

def collect_human_feedback(context: str) -> str:
    """Collect feedback from human user."""
    if os.environ.get("COST_PERF"):
        return ""
    print(f"\nüí¨ FEEDBACK REQUEST")
    print(f"Context: {context}")
    print(f"Your feedback (or press Enter to skip): ")
    
    try:
        feedback = input().strip()
        if feedback:
            logger.info(f"üìù Human feedback collected: {feedback[:50]}...")
            return feedback
        else:
            logger.info("üìù No feedback provided")
            return ""
    except KeyboardInterrupt:
        logger.info("üìù Feedback collection interrupted")
        return ""

# ============================================================================
# Advanced LangGraph Workflow with All Features
# ============================================================================

async def create_advanced_research_workflow(config: AdvancedConfig, lg_interceptor: LangGraphInterceptor):
    """Create an advanced research workflow with all modern LangGraph features."""
    try:
        # Import all required LangGraph components
        from langchain_core.tools import tool
        from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
        from langgraph.graph import StateGraph, START, END
        from langgraph.checkpoint.memory import MemorySaver
        from langgraph.prebuilt import ToolNode
        from langgraph.types import Command
        
        logger.info("üèóÔ∏è Creating advanced research workflow...")
        
        # Initialize model (Azure OpenAI if env set, else Gemini)
        model = get_llm()
        logger.info("‚úÖ LLM configured (Azure OpenAI or Gemini from env)")
        
        # Create advanced checkpointer
        if config.USE_SQLITE_CHECKPOINT:
            try:
                from langgraph.checkpoint.sqlite import SqliteSaver
                # Ensure checkpoint directory exists
                Path(config.CHECKPOINT_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
                checkpointer = SqliteSaver.from_conn_string(config.CHECKPOINT_DB_PATH)
                logger.info(f"‚úÖ SQLite checkpointer: {config.CHECKPOINT_DB_PATH}")
            except ImportError:
                logger.info("‚ö†Ô∏è SQLite checkpointing not available, using memory checkpointing")
                checkpointer = MemorySaver()
                logger.info("‚úÖ Memory checkpointer (fallback)")
        else:
            checkpointer = MemorySaver()
            logger.info("‚úÖ Memory checkpointer")
        
        # Create tools: when COST_PERF=1 use same LLM-powered tools as researched for fair comparison
        if os.environ.get("COST_PERF"):
            @tool
            def web_search(query: str, depth: str = "basic") -> str:
                """Real LLM-powered web search (same as researched for cost-perf)."""
                import asyncio
                import json
                results = asyncio.run(advanced_web_search_with_llm(query, depth, model))
                return json.dumps(results, indent=2)
            
            @tool
            def deep_analysis(source_data: str, analysis_type: str = "mixed") -> str:
                """Real LLM-powered deep analysis (same as researched for cost-perf)."""
                import asyncio
                import json
                source_dict = json.loads(source_data) if isinstance(source_data, str) else source_data
                result = asyncio.run(deep_analysis_with_llm(source_dict, analysis_type, model))
                return json.dumps(result, indent=2)
            
            @tool
            def synthesis(analysis_data: str, mode: str = "comprehensive") -> str:
                """Real LLM-powered synthesis (same as researched for cost-perf)."""
                import asyncio
                import json
                analyses = json.loads(analysis_data) if isinstance(analysis_data, str) else [analysis_data]
                result = asyncio.run(synthesis_engine_with_llm(analyses, mode, model))
                return json.dumps(result, indent=2)
        else:
            @tool
            def web_search(query: str, depth: str = "basic") -> List[Dict[str, Any]]:
                """Advanced web search with depth control."""
                return advanced_web_search(query, depth)
            
            @tool
            def deep_analysis(source_data: str, analysis_type: str = "mixed") -> Dict[str, Any]:
                """Perform deep analysis on research data."""
                import json
                source_dict = json.loads(source_data) if isinstance(source_data, str) else source_data
                return deep_analysis_tool(source_dict, analysis_type)
            
            @tool
            def synthesis(analysis_data: str, mode: str = "comprehensive") -> Dict[str, Any]:
                """Synthesize multiple analyses into unified insights."""
                import json
                analyses = json.loads(analysis_data) if isinstance(analysis_data, str) else [analysis_data]
                return synthesis_engine(analyses, mode)
        
        tools = [web_search, deep_analysis, synthesis]
        
        # Create the advanced state graph
        workflow = StateGraph(ResearchState)
        
        # Define advanced workflow nodes
        def planning_node(state: ResearchState) -> ResearchState:
            """Advanced planning with human approval."""
            logger.info("üìã Planning phase started")
            
            # Check if human approval is required for planning
            if require_human_approval(
                "Create Research Plan",
                {"query": state["query"], "complexity": "medium"},
                "medium"
            ):
                state["current_step"] = "research"
                state["coordination_log"].append(f"Planning approved at {datetime.now()}")
            else:
                state["current_step"] = "review"
                state["coordination_log"].append(f"Planning rejected at {datetime.now()}")
            
            state["last_update"] = datetime.now()
            return state
        
        def research_node(state: ResearchState) -> ResearchState:
            """Advanced research with multi-source search. Uses same tools as researched when COST_PERF=1."""
            logger.info("üîç Advanced research phase")
            
            try:
                # Use tool invocation (same path as researched; tools are LLM-powered when COST_PERF=1)
                res = web_search.invoke({"query": state["query"], "depth": "comprehensive"})
                search_results = json.loads(res) if isinstance(res, str) else res
                state["search_results"] = search_results
                state["current_step"] = "analysis"
                
                # Log coordination
                state["coordination_log"].append(f"Research completed: {len(search_results)} sources found")
                
            except Exception as e:
                logger.error(f"Research failed: {e}")
                state["error_count"] += 1
                state["last_error"] = str(e)
                state["recovery_attempts"].append(f"Research retry at {datetime.now()}")
                
                # Trigger error recovery if enabled
                if len(state["recovery_attempts"]) < AdvancedConfig.MAX_RECOVERY_ATTEMPTS:
                    state["current_step"] = "research"  # Retry
                else:
                    state["current_step"] = "review"    # Give up and review
            
            state["last_update"] = datetime.now()
            return state
        
        def analysis_node(state: ResearchState) -> ResearchState:
            """Advanced analysis with multiple methodologies. Uses same tools as researched when COST_PERF=1."""
            logger.info("üî¨ Advanced analysis phase")
            
            try:
                analysis_results = []
                
                # Use tool invocation (same path as researched; tools are LLM-powered when COST_PERF=1)
                for result in state["search_results"][:3]:  # Top 3 results
                    try:
                        res = deep_analysis.invoke({"source_data": json.dumps(result), "analysis_type": "mixed"})
                        analysis = json.loads(res) if isinstance(res, str) else res
                        analysis_results.append(analysis)
                    except Exception as e:
                        logger.warning(f"Analysis failed for {result.get('title', 'Unknown')}: {e}")
                        state["error_count"] += 1
                
                state["analysis_results"] = analysis_results
                state["agent_outputs"]["analysis"] = len(analysis_results)
                state["coordination_log"].append(f"Analysis completed: {len(analysis_results)} analyses")
                
                # Check if synthesis is needed
                if len(analysis_results) > 1:
                    state["current_step"] = "synthesis"
                else:
                    state["current_step"] = "review"
                    
            except Exception as e:
                logger.error(f"Analysis failed: {e}")
                state["error_count"] += 1
                state["last_error"] = str(e)
                state["current_step"] = "review"
            
            state["last_update"] = datetime.now()
            return state
        
        def synthesis_node(state: ResearchState) -> ResearchState:
            """Advanced synthesis with human input. Uses same tools as researched when COST_PERF=1."""
            logger.info("üîÑ Advanced synthesis phase")
            
            try:
                # Use tool invocation (same path as researched; tools are LLM-powered when COST_PERF=1)
                res = synthesis.invoke({"analysis_data": json.dumps(state["analysis_results"]), "mode": "comprehensive"})
                synthesis_result = json.loads(res) if isinstance(res, str) else res
                state["agent_outputs"]["synthesis"] = synthesis_result
                
                # Request human feedback on synthesis
                feedback = collect_human_feedback(
                    f"Synthesis complete with {synthesis_result['confidence_level']:.1%} confidence. "
                    f"Key findings: {synthesis_result['unified_findings'][:2]}"
                )
                
                if feedback:
                    state["user_feedback"].append(feedback)
                
                state["coordination_log"].append("Synthesis completed with human feedback")
                state["current_step"] = "review"
                
            except Exception as e:
                logger.error(f"Synthesis failed: {e}")
                state["error_count"] += 1
                state["last_error"] = str(e)
                state["current_step"] = "review"
            
            state["last_update"] = datetime.now()
            return state
        
        def review_node(state: ResearchState) -> ResearchState:
            """Advanced review with quality assessment."""
            logger.info("üìä Advanced review phase")
            
            # Calculate quality metrics
            quality_score = 0.0
            if state["search_results"]:
                quality_score += 0.3
            if state["analysis_results"]:
                quality_score += 0.4
            if state["agent_outputs"].get("synthesis"):
                quality_score += 0.3
            
            # Human approval for completion
            completion_details = {
                "quality_score": quality_score,
                "sources": len(state["search_results"]),
                "analyses": len(state["analysis_results"]),
                "errors": state["error_count"],
                "synthesis": bool(state["agent_outputs"].get("synthesis"))
            }
            
            if require_human_approval(
                "Complete Research Workflow",
                completion_details,
                "low" if quality_score > 0.7 else "medium"
            ):
                state["current_step"] = "completed"
                state["coordination_log"].append("Workflow completed with approval")
            else:
                # Human requested changes
                feedback = collect_human_feedback("What changes would you like?")
                if feedback:
                    state["user_feedback"].append(feedback)
                
                # Route back based on feedback (simplified logic)
                if "search" in feedback.lower():
                    state["current_step"] = "research"
                elif "analysis" in feedback.lower():
                    state["current_step"] = "analysis"
                else:
                    state["current_step"] = "completed"  # Complete anyway
                    
                state["coordination_log"].append("Human requested modifications")
            
            state["last_update"] = datetime.now()
            return state
        
        def human_interaction_node(state: ResearchState) -> ResearchState:
            """Handle human interactions and interrupts."""
            logger.info("üë§ Human interaction node")
            
            # This node handles any pending human interactions
            if state.get("pending_approval"):
                approval = require_human_approval(
                    state["pending_approval"],
                    {"context": "Human interaction required"},
                    "medium"
                )
                
                state["approval_history"].append({
                    "action": state["pending_approval"],
                    "approved": approval,
                    "timestamp": datetime.now().isoformat()
                })
                
                state["pending_approval"] = None
            
            # Continue to next logical step
            state["current_step"] = "review"
            state["last_update"] = datetime.now()
            return state
        
        # Add all nodes to the workflow
        workflow.add_node("planning", planning_node)
        workflow.add_node("research", research_node) 
        workflow.add_node("analysis", analysis_node)
        workflow.add_node("synthesis", synthesis_node)
        workflow.add_node("review", review_node)
        workflow.add_node("human_interaction", human_interaction_node)
        
        # Define advanced conditional routing
        def route_from_planning(state: ResearchState) -> str:
            """Route from planning based on approval."""
            if state["current_step"] == "research":
                return "research"
            else:
                return "review"
        
        def route_from_research(state: ResearchState) -> str:
            """Route from research based on results."""
            if state["current_step"] == "analysis" and state["search_results"]:
                return "analysis"
            elif state["error_count"] > 0 and len(state["recovery_attempts"]) < 3:
                return "research"  # Retry
            else:
                return "review"
        
        def route_from_analysis(state: ResearchState) -> str:
            """Route from analysis based on results."""
            if state["current_step"] == "synthesis":
                return "synthesis"
            else:
                return "review"
        
        def route_from_synthesis(state: ResearchState) -> str:
            """Route from synthesis."""
            return "review"
        
        def route_from_review(state: ResearchState) -> str:
            """Route from review based on completion status."""
            if state["current_step"] == "completed":
                return END
            elif state.get("pending_approval"):
                return "human_interaction"
            else:
                # Route back to appropriate node based on feedback
                return state["current_step"]
        
        # Set up workflow routing
        workflow.set_entry_point("planning")
        workflow.add_conditional_edges("planning", route_from_planning)
        workflow.add_conditional_edges("research", route_from_research)
        workflow.add_conditional_edges("analysis", route_from_analysis) 
        workflow.add_conditional_edges("synthesis", route_from_synthesis)
        workflow.add_conditional_edges("review", route_from_review)
        workflow.add_edge("human_interaction", "review")
        
        # Compile workflow with checkpointer
        compiled_workflow = workflow.compile(
            checkpointer=checkpointer,
            interrupt_before=["human_interaction"],  # Allow interrupts
            interrupt_after=["review"]  # Allow review interrupts
        )
        
        logger.info("‚úÖ Advanced workflow created successfully")
        logger.info(f"   ‚Ä¢ Nodes: {len(workflow.nodes)} advanced processing nodes")
        logger.info(f"   ‚Ä¢ Checkpointing: {'SQLite' if config.USE_SQLITE_CHECKPOINT else 'Memory'}")
        logger.info(f"   ‚Ä¢ Human-in-the-loop: {'Enabled' if config.REQUIRE_HUMAN_APPROVAL else 'Disabled'}")
        logger.info(f"   ‚Ä¢ Error recovery: {'Enabled' if config.AUTO_RECOVERY_ENABLED else 'Disabled'}")
        
        return compiled_workflow, checkpointer
        
    except Exception as e:
        logger.error(f"Failed to create advanced workflow: {e}")
        raise

# ============================================================================
# Advanced Streaming Execution with Full Monitoring
# ============================================================================

async def execute_advanced_workflow_with_monitoring(workflow, checkpointer, query: str, lg_interceptor: LangGraphInterceptor):
    """Execute advanced workflow with comprehensive monitoring."""
    logger.info(f"üöÄ Starting advanced research workflow: {query}")
    
    # Create unique thread for this execution
    import uuid
    thread_id = f"advanced_{uuid.uuid4().hex[:8]}"
    config = {"configurable": {"thread_id": thread_id}}
    
    # Initialize advanced state
    initial_state: ResearchState = {
        "messages": [],
        "current_step": "planning",
        "query": query,
        "search_results": [],
        "analysis_results": [],
        "pending_approval": None,
        "user_feedback": [],
        "approval_history": [],
        "active_agents": ["research", "analysis", "synthesis"],
        "agent_outputs": {},
        "coordination_log": [f"Workflow started for query: {query}"],
        "error_count": 0,
        "recovery_attempts": [],
        "last_error": None,
        "execution_id": thread_id,
        "start_time": datetime.now(),
        "last_update": datetime.now()
    }
    
    print(f"\nüéØ Advanced Research Query: {query}")
    print("=" * 80)
    print("Features: Human-in-the-Loop ‚Ä¢ Advanced Checkpointing ‚Ä¢ Error Recovery ‚Ä¢ Multi-Agent")
    print("=" * 80)
    
    # Execution metrics
    total_events = 0
    node_executions = 0
    human_interactions = 0
    checkpoint_saves = 0
    
    try:
        print(f"\nüì° Advanced Event Stream (Thread: {thread_id}):")
        print("-" * 60)
        
        # Stream events with advanced monitoring
        async for event in workflow.astream_events(
            initial_state,
            config=config,
            version="v1"
        ):
            total_events += 1
            event_type = event.get("event", "unknown")
            event_name = event.get("name", "unknown")
            
            # Handle different event types with advanced logging
            if event_type == "on_chain_start" and "node" in event_name:
                node_executions += 1
                node_name = event.get("data", {}).get("input", {}).get("current_step", "unknown")
                print(f"üîÑ Node #{node_executions}: {node_name} starting...")
                
                # Track with aigie
                lg_interceptor.track_human_interaction(
                    "node_execution",
                    {
                        "node_name": node_name,
                        "execution_id": thread_id,
                        "timestamp": datetime.now()
                    }
                )
                
            elif event_type == "on_chain_end" and "node" in event_name:
                output = event.get("data", {}).get("output", {})
                current_step = output.get("current_step", "unknown")
                error_count = output.get("error_count", 0)
                
                print(f"   ‚úÖ Node completed ‚Üí {current_step}")
                if error_count > 0:
                    print(f"   ‚ö†Ô∏è  Errors detected: {error_count}")
                
            elif event_type == "on_checkpoint_save":
                checkpoint_saves += 1
                print(f"üíæ Checkpoint #{checkpoint_saves} saved")
                
                # Track checkpoint operation
                lg_interceptor.track_human_interaction(
                    "checkpoint_save",
                    {
                        "thread_id": thread_id,
                        "save_count": checkpoint_saves,
                        "timestamp": datetime.now()
                    }
                )
                
            elif "human" in event_name.lower():
                human_interactions += 1
                print(f"üë§ Human Interaction #{human_interactions}")
            
            # Progress updates
            if total_events % 10 == 0:
                print(f"üìä Progress: {total_events} events, {node_executions} nodes, {human_interactions} human interactions")
        
        print(f"\nüéâ Advanced workflow completed!")
        print(f"üìà Final metrics:")
        print(f"   ‚Ä¢ Total events: {total_events}")
        print(f"   ‚Ä¢ Node executions: {node_executions}")
        print(f"   ‚Ä¢ Human interactions: {human_interactions}")
        print(f"   ‚Ä¢ Checkpoints saved: {checkpoint_saves}")
        
        # Get final state
        final_state = await workflow.aget_state(config)
        state = final_state.values
        
        print(f"\nüìã Final Results:")
        print(f"   ‚Ä¢ Status: {state.get('current_step', 'unknown')}")
        print(f"   ‚Ä¢ Sources found: {len(state.get('search_results', []))}")
        print(f"   ‚Ä¢ Analyses completed: {len(state.get('analysis_results', []))}")
        print(f"   ‚Ä¢ Errors encountered: {state.get('error_count', 0)}")
        print(f"   ‚Ä¢ User feedback items: {len(state.get('user_feedback', []))}")
        print(f"   ‚Ä¢ Approvals given: {len(state.get('approval_history', []))}")
        
        # Show coordination log
        if state.get('coordination_log'):
            print(f"\nüìú Coordination Log:")
            for log_entry in state['coordination_log'][-5:]:  # Last 5 entries
                print(f"   ‚Ä¢ {log_entry}")
        
        return {
            "success": True,
            "thread_id": thread_id,
            "total_events": total_events,
            "node_executions": node_executions,
            "human_interactions": human_interactions,
            "checkpoints": checkpoint_saves,
            "final_state": state
        }
        
    except Exception as e:
        logger.error(f"Advanced workflow failed: {e}")
        return {
            "success": False,
            "error": str(e),
            "thread_id": thread_id,
            "total_events": total_events,
            "node_executions": node_executions,
            "human_interactions": human_interactions
        }

# ============================================================================
# Main Advanced Demo
# ============================================================================

async def main():
    """Main demonstration of advanced LangGraph features with aigie monitoring."""
    print("üöÄ Advanced LangGraph Features with Aigie Monitoring")
    print("=" * 70)
    print("üåü Features: Human-in-the-Loop ‚Ä¢ SQLite Checkpointing ‚Ä¢ Error Recovery ‚Ä¢ Multi-Agent")
    print("=" * 70)
    
    try:
        # Initialize enhanced aigie monitoring
        print("\nüìä Initializing Enhanced Aigie System...")
        
        error_detector = AsyncErrorDetector(
            enable_performance_monitoring=True,
            enable_resource_monitoring=True,
            enable_gemini_analysis=True
        )
        
        aigie_logger = AigieLogger()
        
        # Create advanced interceptors
        lc_interceptor = LangChainInterceptor(error_detector, aigie_logger)
        lg_interceptor = LangGraphInterceptor(error_detector, aigie_logger)
        
        # Start comprehensive monitoring
        error_detector.start_monitoring()
        lc_interceptor.start_intercepting()
        lg_interceptor.start_intercepting()
        
        print("‚úÖ Advanced monitoring initialized:")
        print("   ‚Ä¢ Real-time error detection and AI-powered remediation")
        print("   ‚Ä¢ Human interaction tracking and approval workflows")
        print("   ‚Ä¢ Advanced checkpoint monitoring with SQLite")
        print("   ‚Ä¢ Multi-agent coordination pattern analysis")
        print("   ‚Ä¢ Stream event analysis with error recovery")
        
        # Create advanced configuration
        config = AdvancedConfig()
        
        # Create advanced workflow
        print(f"\nüèóÔ∏è  Creating Advanced Research Workflow...")
        workflow, checkpointer = await create_advanced_research_workflow(config, lg_interceptor)
        
        # Execute advanced research
        research_queries = [
            "quantum computing applications in drug discovery and molecular simulation",
            "AI ethics and bias mitigation in healthcare decision-making systems",
            "sustainable AI and green computing for large-scale machine learning"
        ]
        
        import random
        selected_query = random.choice(research_queries)
        print(f"\nüéØ Selected Research Focus: {selected_query}")
        
        # Execute with advanced monitoring
        result = await execute_advanced_workflow_with_monitoring(
            workflow, checkpointer, selected_query, lg_interceptor
        )
        
        # Show comprehensive results
        print(f"\nüìä Advanced Execution Results:")
        print(f"   Success: {'‚úÖ' if result['success'] else '‚ùå'}")
        print(f"   Thread ID: {result['thread_id']}")
        print(f"   Total Events: {result['total_events']}")
        print(f"   Node Executions: {result['node_executions']}")
        print(f"   Human Interactions: {result['human_interactions']}")
        print(f"   Checkpoints: {result.get('checkpoints', 0)}")
        
        if not result['success']:
            print(f"   Error: {result.get('error', 'Unknown error')}")
        
        # Display comprehensive aigie monitoring results
        print(f"\nüîç Comprehensive Aigie Analysis:")
        print("=" * 50)
        
        # LangChain monitoring results
        lc_status = lc_interceptor.get_interception_status()
        print(f"LangChain Monitoring:")
        print(f"   ‚Ä¢ Intercepted Classes: {len(lc_status['intercepted_classes'])}")
        print(f"   ‚Ä¢ Active Methods: {len(lc_status['patched_methods'])}")
        print(f"   ‚Ä¢ Component Coverage: {lc_status['target_classes']}")
        
        # Advanced LangGraph monitoring results
        lg_status = lg_interceptor.get_interception_status()
        print(f"\nAdvanced LangGraph Monitoring:")
        print(f"   ‚Ä¢ Tracked Graphs: {lg_status['tracked_graphs']}")
        print(f"   ‚Ä¢ Streaming Sessions: {lg_status['streaming_sessions']}")
        print(f"   ‚Ä¢ Active Streams: {lg_status['active_streams']}")
        print(f"   ‚Ä¢ Event History: {lg_status['event_history_size']}")
        print(f"   ‚Ä¢ Human Interactions: {lg_status['human_interactions']}")
        print(f"   ‚Ä¢ Checkpoint Operations: {lg_status['checkpoint_operations']}")
        
        # Detailed streaming analysis
        if lg_status['streaming_sessions'] > 0:
            streaming_analysis = lg_interceptor.get_streaming_analysis()
            print(f"\nStreaming Analysis:")
            print(f"   ‚Ä¢ Total Sessions: {streaming_analysis['total_sessions']}")
            print(f"   ‚Ä¢ Completed: {streaming_analysis['completed_sessions']}")
            print(f"   ‚Ä¢ With Errors: {streaming_analysis['error_sessions']}")
            print(f"   ‚Ä¢ Total Events Processed: {streaming_analysis['total_events']}")
            
            if streaming_analysis['recent_event_types']:
                print(f"   ‚Ä¢ Event Distribution: {streaming_analysis['recent_event_types']}")
        
        # Checkpoint analysis
        if lg_status['checkpoint_operations'] > 0:
            checkpoint_analysis = lg_interceptor.get_checkpoint_analysis()
            print(f"\nCheckpoint Analysis:")
            print(f"   ‚Ä¢ Total Operations: {checkpoint_analysis['total_operations']}")
            print(f"   ‚Ä¢ Success Rate: {checkpoint_analysis['success_rate']:.1f}%")
            print(f"   ‚Ä¢ Operation Types: {checkpoint_analysis['operation_types']}")
        
        # Human interaction analysis
        if lg_status['human_interactions'] > 0:
            human_analysis = lg_interceptor.get_human_interaction_analysis()
            print(f"\nHuman-in-the-Loop Analysis:")
            print(f"   ‚Ä¢ Total Interactions: {human_analysis['total_interactions']}")
            print(f"   ‚Ä¢ Interaction Types: {human_analysis['interaction_types']}")
        
        # Error and health analysis
        error_summary = error_detector.get_error_summary(window_minutes=60)
        print(f"\nError Detection Summary:")
        print(f"   ‚Ä¢ Errors Detected (1h): {error_summary['total_errors']}")
        
        if error_summary['total_errors'] > 0:
            print(f"   ‚Ä¢ Severity Breakdown: {error_summary['severity_distribution']}")
            print(f"   ‚Ä¢ Component Breakdown: {error_summary['component_distribution']}")
            print(f"   ‚Ä¢ AI-Analyzed: {error_summary.get('gemini_analyzed', 0)}")
            print(f"   ‚Ä¢ Auto-Retried: {error_summary.get('retry_attempts', 0)}")
        
        # System health overview
        health = error_detector.get_system_health()
        print(f"\nSystem Health Overview:")
        print(f"   ‚Ä¢ Monitoring Status: {'üü¢ Active' if health['is_monitoring'] else 'üî¥ Inactive'}")
        print(f"   ‚Ä¢ Recent Errors (5min): {health['recent_errors']}")
        
        if 'performance_summary' in health:
            perf = health['performance_summary']
            print(f"   ‚Ä¢ Avg Response Time: {perf.get('avg_execution_time', 'N/A')}")
            print(f"   ‚Ä¢ Memory Efficiency: {perf.get('avg_memory_usage', 'N/A')}")
        
        # Stop monitoring
        print(f"\nüõë Stopping Advanced Monitoring...")
        error_detector.stop_monitoring()
        lc_interceptor.stop_intercepting()
        lg_interceptor.stop_intercepting()
        
        print(f"\nüèÜ Advanced LangGraph Demo Completed Successfully!")
        print("=" * 70)
        print("üéØ Advanced Features Demonstrated:")
        print("‚úì Human-in-the-Loop workflows with approval checkpoints")
        print("‚úì Advanced SQLite checkpointing with thread management")
        print("‚úì Error recovery with conditional routing")
        print("‚úì Multi-agent coordination and state management")
        print("‚úì Real-time streaming with comprehensive event monitoring")
        print("‚úì Enhanced aigie monitoring of all modern components")
        print("‚úì AI-powered error analysis and remediation")
        print("‚úì Advanced analytics and performance metrics")
        
        print(f"\nüí° Key Insights:")
        print(f"‚Ä¢ Modern LangGraph provides powerful orchestration capabilities")
        print(f"‚Ä¢ Human-in-the-loop enables reliable AI decision-making")
        print(f"‚Ä¢ Advanced checkpointing ensures workflow persistence")
        print(f"‚Ä¢ Aigie provides comprehensive monitoring across all components")
        print(f"‚Ä¢ Real-time analytics enable proactive error management")
        
    except Exception as e:
        logger.error(f"Advanced demo failed: {e}")
        print(f"\n‚ùå Advanced demo failed: {e}")
        print(f"\nüîß Troubleshooting:")
        print(f"‚Ä¢ Check API keys: GEMINI_API_KEY")
        print(f"‚Ä¢ Install latest: pip install -U langchain langgraph langchain-google-genai")
        print(f"‚Ä¢ Ensure SQLite permissions for checkpointing")
        print(f"‚Ä¢ Verify network connectivity for tools")


class UsageAggregator(BaseCallbackHandler):
    """Callback handler that aggregates LLM token usage from on_llm_end."""

    def __init__(self):
        super().__init__()
        self.input_tokens = 0
        self.output_tokens = 0

    def on_llm_end(self, response, **kwargs):
        try:
            out = getattr(response, "llm_output", None) or {}
            usage = out.get("token_usage") or out.get("usage") or {}
            if isinstance(usage, dict):
                self.input_tokens += int(usage.get("input_tokens") or usage.get("prompt_tokens") or 0)
                self.output_tokens += int(usage.get("output_tokens") or usage.get("completion_tokens") or 0)
            for gen_list in getattr(response, "generations", []) or []:
                for gen in gen_list:
                    msg = getattr(gen, "message", None)
                    if msg and hasattr(msg, "response_metadata"):
                        meta = msg.response_metadata or {}
                        u = meta.get("token_usage") or meta.get("usage_metadata") or {}
                        if isinstance(u, dict):
                            self.input_tokens += int(u.get("input_tokens") or u.get("prompt_tokens") or 0)
                            self.output_tokens += int(u.get("output_tokens") or u.get("completion_tokens") or 0)
        except Exception:
            pass


async def run_cost_perf_mode():
    """Run the LangGraph workflow once and write cost-perf-results.json to clone root."""
    try:
        from dotenv import load_dotenv
        env_path = os.getenv("COST_PERF_ENV")
        if env_path and os.path.isfile(env_path):
            load_dotenv(env_path)
        else:
            clone_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            for rel in ["../../../master.env", "../../master.env", "master.env"]:
                p = os.path.join(clone_root, rel)
                if os.path.isfile(p):
                    load_dotenv(p)
                    break
    except Exception:
        pass
    config = AdvancedConfig(REQUIRE_HUMAN_APPROVAL=False)
    error_detector = ErrorDetector()
    aigie_logger = AigieLogger()
    lg_interceptor = LangGraphInterceptor(error_detector, aigie_logger)
    compiled_workflow, checkpointer = await create_advanced_research_workflow(config, lg_interceptor)
    usage = UsageAggregator()
    thread_id = f"cost-perf-{datetime.now().strftime('%Y%m%d%H%M%S')}"
    query = "What is 2+2? Reply briefly."
    input_id = os.environ.get("COST_PERF_INPUT_ID")
    if input_id:
        query = query + " [cost-perf-id=" + str(input_id) + "]"
    initial_state = {
        "messages": [],
        "query": query,
        "current_step": "planning",
        "search_results": [],
        "analysis_results": [],
        "pending_approval": None,
        "user_feedback": [],
        "approval_history": [],
        "active_agents": ["research", "analysis", "synthesis"],
        "agent_outputs": {},
        "coordination_log": [f"Workflow started for cost-perf"],
        "error_count": 0,
        "recovery_attempts": [],
        "last_error": None,
        "execution_id": thread_id,
        "start_time": datetime.now(),
        "last_update": datetime.now(),
    }
    start = time.perf_counter()
    await compiled_workflow.ainvoke(
        initial_state,
        config={
            "configurable": {"thread_id": thread_id},
            "callbacks": [usage],
        },
    )
    duration_ms = (time.perf_counter() - start) * 1000
    total = usage.input_tokens + usage.output_tokens
    out = {
        "durationMs": round(duration_ms, 2),
        "usage": {
            "inputTokens": usage.input_tokens,
            "outputTokens": usage.output_tokens,
            "totalTokens": total,
        },
    }
    clone_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    results_path = os.path.join(clone_root, "cost-perf-results.json")
    with open(results_path, "w") as f:
        json.dump(out, f, indent=2)
    logger.info("Cost-perf run complete: %s", results_path)


if __name__ == "__main__":
    if os.environ.get("COST_PERF"):
        asyncio.run(run_cost_perf_mode())
        sys.exit(0)
    asyncio.run(main())
