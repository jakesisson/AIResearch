apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  namespace: ollama
  labels:
    app: ollama
spec:
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      runtimeClassName: nvidia
      volumes:
        - name: ollama-models-volume
          persistentVolumeClaim:
            claimName: ollama-models
        - name: init-script
          configMap:
            name: ollama-init-script
            defaultMode: 0755
        # - name: sd-models-volume
        #   persistentVolumeClaim:
        #     claimName: sd-models
        - name: generated-images
          persistentVolumeClaim:
            claimName: generated-images
        - name: code-base
          persistentVolumeClaim:
            claimName: code-base
        # - name: llama-cpp
        #   hostPath:
        #     path: /llama.cpp
        #     type: DirectoryOrCreate
        - name: models
          hostPath:
            path: /models
            type: DirectoryOrCreate
      containers:
        - name: ollama
          image: 192.168.0.71:31500/inference:composer
          imagePullPolicy: Always
          ports:
            - name: ollama
              containerPort: 11434
              protocol: TCP
            - name: sd
              containerPort: 8000
              protocol: TCP
          resources:
            requests:
              memory: "24Gi"
              cpu: "16"
              nvidia.com/gpu: "1"
            limits:
              memory: "30Gi"
              cpu: "20"
              nvidia.com/gpu: "1"
          volumeMounts:
            - name: ollama-models-volume
              mountPath: /root/.ollama
            # - name: sd-models-volume
            #   mountPath: /root/.cache/huggingface/hub
            - name: init-script
              mountPath: /scripts
            - name: generated-images
              mountPath: /root/images
            - name: code-base
              mountPath: /app
            # - name: llama-cpp
            #   mountPath: /llama.cpp
            - name: models
              mountPath: /models
          env:
            - name: PYTHONPATH
              value: "/app"
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token

            # Authentication configuration
            - name: AUTH_ISSUER
              value: "https://auth.longstorymedia.com"
            - name: AUTH_AUDIENCE
              value: "lsm-client"
            - name: AUTH_CLIENT_ID
              value: "lsm-client"
            - name: AUTH_CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: auth-client
                  key: client_secret
            - name: AUTH_JWKS_URI
              value: "https://auth.longstorymedia.com/keys"

            # Database configuration
            - name: DB_HOST
              value: "192.168.0.71"
            - name: DB_PORT
              value: "32345"
            - name: DB_USER
              value: "lsm"
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-credentials
                  key: password
            - name: DB_NAME
              value: "llmmll"
            - name: DB_SSLMODE
              value: "disable"

            # Redis configuration
            - name: REDIS_ENABLED
              value: "true"
            - name: REDIS_HOST
              value: "192.168.0.71"
            - name: REDIS_PORT
              value: "32346"
            - name: REDIS_DB
              value: "0"
            - name: REDIS_CONVERSATION_TTL
              value: "360"
            - name: REDIS_MESSAGE_TTL
              value: "180"
            - name: REDIS_SUMMARY_TTL
              value: "720"
            - name: REDIS_POOL_SIZE
              value: "10"
            - name: REDIS_MIN_IDLE_CONNECTIONS
              value: "2"
            - name: REDIS_CONNECT_TIMEOUT
              value: "5"

            # Summarization configuration
            - name: MESSAGES_BEFORE_SUMMARY
              value: "6"
            - name: SUMMARIES_BEFORE_CONSOLIDATION
              value: "3"
            - name: SUMMARY_MODEL
              value: "qwen3:0.6b"
            - name: SUMMARY_SYSTEM_PROMPT
              value: "compress the following conversation so far into a concise paragraph. Include key points and conclusions, but omit redundant details. The summary will be used as context for future interaction. It should be as small as possible and does not need to be human readable."
            - name: MAX_SUMMARY_LEVELS
              value: "3"
            - name: SUMMARY_WEIGHT_COEFFICIENT
              value: "192.168.0.71"

            # Image generation configuration
            - name: IMAGE_GENERATION_ENABLED
              value: "true"
            - name: IMAGE_DIR
              value: "/root/images"
            - name: MAX_IMAGE_SIZE
              value: "2048"
            - name: IMAGE_RETENTION_HOURS
              value: "24"

            # Internal security configuration
            - name: INTERNAL_API_KEY
              valueFrom:
                secretKeyRef:
                  name: internal-api-key
                  key: api_key
            - name: INTERNAL_ALLOWED_IPS
              value: "192.168.0.0/24,10.43.0.0/16"

            # Logging configuration
            - name: LOG_LEVEL
              value: "debug"
            - name: FORCE_COLOR
              value: "1"
            # API versioning configurationEL
            - name: API_VERSION
              value: "v1"
            - name: CUDA_VISIBLE_DEVICES
              value: "0,1,2" # Explicitly list available devices
            - name: CUDA_DEVICE_ORDER
              value: "PCI_BUS_ID"
            # Python memory optimizations
            - name: PYTHONMALLOC
              value: "malloc"
            - name: MALLOC_ARENA_MAX
              value: "2"
            # Logging configuration for debugging
            - name: GGML_LOG_LEVEL
              value: "2"
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            # Search API keys configuration
            - name: SEARX_HOST
              value: "http://searxng.searxng.svc.cluster.local:8080"

  strategy:
    type: Recreate
