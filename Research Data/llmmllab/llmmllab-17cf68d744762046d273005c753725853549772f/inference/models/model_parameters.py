# Code generated by schema2code at 2025-10-20 19:10:59. DO NOT EDIT.


from typing import List, Dict, Optional, Any, Union
from datetime import datetime, date, time, timedelta
from pydantic import BaseModel, Field, AnyUrl, EmailStr, conint, confloat



class ModelParameters(BaseModel):
    """Parameters for configuring a language model"""
    num_ctx: Optional[int] = Field(default=None, description="Size of the context window")
    """Size of the context window"""
    repeat_last_n: Optional[int] = Field(default=None, description="Number of tokens to consider for repetition penalties")
    """Number of tokens to consider for repetition penalties"""
    repeat_penalty: Optional[float] = Field(default=None, description="Penalty for repetitions")
    """Penalty for repetitions"""
    temperature: Optional[float] = Field(default=None, description="Sampling temperature; higher values produce more creative outputs")
    """Sampling temperature; higher values produce more creative outputs"""
    seed: Optional[int] = Field(default=None, description="Random seed for reproducibility")
    """Random seed for reproducibility"""
    stop: Optional[List[str]] = Field(default=None, description="Sequences where the model should stop generating")
    """Sequences where the model should stop generating"""
    num_predict: Optional[int] = Field(default=None, description="Maximum number of tokens to predict")
    """Maximum number of tokens to predict"""
    top_k: Optional[int] = Field(default=None, description="Limits next token selection to top K options")
    """Limits next token selection to top K options"""
    top_p: Optional[float] = Field(default=None, description="Limits next token selection to tokens comprising the top P probability mass (nucleus sampling)")
    """Limits next token selection to tokens comprising the top P probability mass (nucleus sampling)"""
    min_p: Optional[float] = Field(default=None, description="Minimum probability threshold for token selection")
    """Minimum probability threshold for token selection"""
    think: Optional[bool] = Field(default=None, description="Whether to enable \"thinking\" mode for the model")
    """Whether to enable \"thinking\" mode for the model"""
    max_tokens: Optional[int] = Field(default=None, description="Maximum number of tokens to generate in a single response")
    """Maximum number of tokens to generate in a single response"""
    n_parts: Optional[int] = Field(default=None, description="Number of parts to split the model into. -1 means auto.")
    """Number of parts to split the model into. -1 means auto."""
    batch_size: Optional[int] = Field(default=None, description="Batch size for processing inputs")
    """Batch size for processing inputs"""
    n_cpu_moe: Optional[int] = Field(default=0, description="Number of MoE (Mixture of Experts) layers to keep on CPU for memory optimization", ge=0)
    """Number of MoE (Mixture of Experts) layers to keep on CPU for memory optimization"""
    reasoning_effort: Optional[str] = Field(default='medium', description="Reasoning effort level for chain-of-thought processing")
    """Reasoning effort level for chain-of-thought processing"""
    flash_attention: Optional[bool] = Field(default=True, description="Enable flash attention optimization for memory efficiency")
    """Enable flash attention optimization for memory efficiency"""

    class Config:
        extra = "ignore"