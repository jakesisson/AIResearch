"BenchmarkResult(score=0.0, total_questions=2, correct_answers=0, detailed_results=[{'question_id': 0, 'subject': 'Chemistry', 'correct_answer': 'B', 'model_answer': 'C', 'extraction_confidence': 0.53, 'eval_confidence': 1.0, 'is_correct': False, 'metadata': {'extracted': 'C', 'expected': 'B', 'extraction_confidence': 0.53, 'evaluation_method': 'exact_match'}, 'response': \"\ud83e\udd14 Processing with LangGraph...\\n\\n<think>\\nOkay, let's try to figure out this question. So the topic is...\"}, {'question_id': 1, 'subject': 'Biology', 'correct_answer': 'C', 'model_answer': 'B', 'extraction_confidence': 0.8, 'eval_confidence': 1.0, 'is_correct': False, 'metadata': {'extracted': 'B', 'expected': 'C', 'extraction_confidence': 0.8, 'evaluation_method': 'exact_match'}, 'response': \"\ud83e\udd14 Processing with LangGraph...\\n\\n<think>\\nOkay, let's tackle this question about CpG islands. Hmm.\\n\\nFi...\"}], metadata={'benchmark': 'GPQA-Diamond', 'description': 'Graduate-level science questions'})"