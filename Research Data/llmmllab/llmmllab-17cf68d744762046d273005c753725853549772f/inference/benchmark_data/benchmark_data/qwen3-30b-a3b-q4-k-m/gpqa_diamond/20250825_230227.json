"BenchmarkResult(score=0.0, total_questions=4, correct_answers=0, detailed_results=[{'question_id': 0, 'subject': 'Chemistry', 'correct_answer': 'B', 'model_answer': 'UNKNOWN', 'extraction_confidence': 0.0, 'eval_confidence': 0.0, 'is_correct': False, 'metadata': {'reason': 'no_answer_extracted'}, 'response': ''}, {'question_id': 1, 'subject': 'Biology', 'correct_answer': 'C', 'model_answer': 'UNKNOWN', 'extraction_confidence': 0.0, 'eval_confidence': 0.0, 'is_correct': False, 'metadata': {'reason': 'no_answer_extracted'}, 'response': ''}, {'question_id': 2, 'subject': 'Physics', 'correct_answer': 'C', 'model_answer': 'UNKNOWN', 'extraction_confidence': 0.0, 'eval_confidence': 0.0, 'is_correct': False, 'metadata': {'reason': 'no_answer_extracted'}, 'response': ''}, {'question_id': 3, 'subject': 'Medicine', 'correct_answer': 'B', 'model_answer': 'UNKNOWN', 'extraction_confidence': 0.0, 'eval_confidence': 0.0, 'is_correct': False, 'metadata': {'reason': 'no_answer_extracted'}, 'response': ''}], metadata={'benchmark': 'GPQA-Diamond', 'description': 'Graduate-level science questions'})"