// Code generated by schema2code at 2025-10-20 19:10:32. DO NOT EDIT.


/**
 * Parameters for configuring a language model
 */
export interface ModelParameters {
  /**
   * Size of the context window
   */
  num_ctx?: number;
  /**
   * Number of tokens to consider for repetition penalties
   */
  repeat_last_n?: number;
  /**
   * Penalty for repetitions
   */
  repeat_penalty?: number;
  /**
   * Sampling temperature; higher values produce more creative outputs
   */
  temperature?: number;
  /**
   * Random seed for reproducibility
   */
  seed?: number;
  /**
   * Sequences where the model should stop generating
   */
  stop?: string[];
  /**
   * Maximum number of tokens to predict
   */
  num_predict?: number;
  /**
   * Limits next token selection to top K options
   */
  top_k?: number;
  /**
   * Limits next token selection to tokens comprising the top P probability mass (nucleus sampling)
   */
  top_p?: number;
  /**
   * Minimum probability threshold for token selection
   */
  min_p?: number;
  /**
   * Whether to enable "thinking" mode for the model
   */
  think?: boolean;
  /**
   * Maximum number of tokens to generate in a single response
   */
  max_tokens?: number;
  /**
   * Number of parts to split the model into. -1 means auto.
   */
  n_parts?: number;
  /**
   * Batch size for processing inputs
   */
  batch_size?: number;
  /**
   * Number of MoE (Mixture of Experts) layers to keep on CPU for memory optimization
   */
  n_cpu_moe?: number;
  /**
   * Reasoning effort level for chain-of-thought processing
   */
  reasoning_effort?: 'low' | 'medium' | 'high';
  /**
   * Enable flash attention optimization for memory efficiency
   */
  flash_attention?: boolean;
}