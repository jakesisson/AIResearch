$schema: http://json-schema.org/draft-07/schema#
title: GPUConfig
description: Configuration for GPU memory management and device allocation
type: object
properties:
  no_kv_offload:
    type: boolean
    description: Force KV cache to CPU instead of GPU (saves VRAM)
    default: false
  gpu_layers:
    type: integer
    description: Explicit number of model layers to place on GPU (-1 means all layers). If unset, heuristic allocation/backoff is used.
    nullable: true
  main_gpu:
    type: integer
    minimum: -1
    description: Main GPU device index (-1 for auto-selection)
    default: -1
  main_gpu_device_id:
    type: string
    description: Device ID/name for main GPU (overrides main_gpu index)
    nullable: true
  tensor_split:
    type: array
    items:
      type: number
      minimum: 0.0
      maximum: 1.0
    description: Fraction of model to put on each GPU (must sum to 1.0)
    nullable: true
  tensor_split_devices:
    type: array
    items:
      type: string
    description: Device IDs/names corresponding to tensor_split fractions
    nullable: true
  split_mode:
    type: string
    enum: ["none", "layer", "row"]
    description: How to split model across devices
    default: "layer"
  offload_kqv:
    type: boolean
    description: Offload key/query/value tensors to GPU (opposite of no_kv_offload)
    default: true
additionalProperties: false
