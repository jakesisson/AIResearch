"""
Script para procesar portfolio.yaml en documentos sem√°nticos para RAG.
Convierte el YAML en chunks optimizados para embeddings y retrieval.
"""
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
import yaml
from pathlib import Path
from typing import List


def process_portfolio_to_chunks(portfolio_path: str) -> List[Document]:
    """
    Procesa el archivo portfolio.yaml y lo convierte en chunks sem√°nticos.
    
    Args:
        portfolio_path: Ruta al archivo portfolio.yaml
        
    Returns:
        Lista de documentos LangChain listos para embeddings
    """
    # Leer YAML
    with open(portfolio_path, 'r', encoding='utf-8') as f:
        data = yaml.safe_load(f)
    
    documents = []
    
    # 1. Informaci√≥n Personal
    personal = data.get('personal_info', {})
    if personal:
        content = f"""
Informaci√≥n Personal:
Nombre: {personal.get('name', 'N/A')}
T√≠tulo: {personal.get('title', 'N/A')}
Email: {personal.get('email', 'N/A')}
Ubicaci√≥n: {personal.get('location', 'N/A')}
LinkedIn: {personal.get('linkedin', 'N/A')}
GitHub: {personal.get('github', 'N/A')}
Sitio Web: {personal.get('website', 'N/A')}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "personal_info",
                "source": "portfolio.yaml"
            }
        ))
    
    # 2. Resumen Profesional
    prof_summary = data.get('professional_summary', {})
    if prof_summary:
        short_summary = prof_summary.get('short', '')
        detailed_summary = prof_summary.get('detailed', '')
        
        content = f"""
Resumen Profesional:

{short_summary}

{detailed_summary}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "professional_summary",
                "source": "portfolio.yaml"
            }
        ))
    
    # 3. Experiencia Laboral (cada empresa es un documento)
    for exp in data.get('experience', []):
        company = exp.get('company', 'N/A')
        position = exp.get('position', 'N/A')
        duration = exp.get('duration', 'N/A')
        location = exp.get('location', 'N/A')
        description = exp.get('description', 'N/A')
        technologies = ', '.join(exp.get('technologies', []))
        projects = ', '.join(exp.get('related_projects', []))
        
        content = f"""
Experiencia Laboral:

Empresa: {company}
Posici√≥n: {position}
Duraci√≥n: {duration}
Ubicaci√≥n: {location}

Descripci√≥n:
{description}

Tecnolog√≠as utilizadas: {technologies}

Proyectos relacionados: {projects}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "experience",
                "company": company,
                "position": position,
                "duration": duration,
                "source": "portfolio.yaml"
            }
        ))
    
    # 4. Educaci√≥n (cada t√≠tulo es un documento)
    for edu in data.get('education', []):
        institution = edu.get('institution', 'N/A')
        degree = edu.get('degree', 'N/A')
        period = edu.get('period', 'N/A')
        details = edu.get('details', '')
        knowledge = edu.get('knowledge_acquired', [])
        
        knowledge_list = '\n'.join([f"- {k}" for k in knowledge])
        
        content = f"""
Educaci√≥n:

Instituci√≥n: {institution}
T√≠tulo: {degree}
Periodo: {period}

{details}

Conocimientos adquiridos:
{knowledge_list}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "education",
                "institution": institution,
                "degree": degree,
                "period": period,
                "source": "portfolio.yaml"
            }
        ))
    
    # 5. Skills por categor√≠a
    for skill_cat in data.get('skills', []):
        category = skill_cat.get('category', 'N/A')
        items = ', '.join(skill_cat.get('items', []))
        
        content = f"""
Habilidades T√©cnicas:

Categor√≠a: {category}

Habilidades: {items}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "skills",
                "category": category,
                "source": "portfolio.yaml"
            }
        ))
    
    # 6. Proyectos Destacados
    for project in data.get('projects', []):
        name = project.get('name', 'N/A')
        company = project.get('company', 'N/A')
        description = project.get('description', 'N/A')
        technologies = ', '.join(project.get('technologies', []))
        
        content = f"""
Proyecto Destacado:

Nombre: {name}
Empresa: {company}

Descripci√≥n:
{description}

Tecnolog√≠as utilizadas: {technologies}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "project",
                "name": name,
                "company": company,
                "source": "portfolio.yaml"
            }
        ))
    
    # 7. Idiomas
    for lang in data.get('languages', []):
        name = lang.get('name', 'N/A')
        level = lang.get('level', 'N/A')
        
        content = f"""
Idioma: {name}
Nivel: {level}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "language",
                "language": name,
                "level": level,
                "source": "portfolio.yaml"
            }
        ))
    
    # 8. Disponibilidad
    availability = data.get('availability', {})
    if availability:
        status = availability.get('status', 'N/A')
        notice_period = availability.get('notice_period', 'N/A')
        remote_work = availability.get('remote_work', 'N/A')
        
        content = f"""
Disponibilidad:

Estado: {status}
Periodo de aviso: {notice_period}
Trabajo remoto: {remote_work}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "availability",
                "source": "portfolio.yaml"
            }
        ))
    
    # 9. Filosof√≠a e Intereses
    for interest in data.get('philosophy_and_interests', []):
        title = interest.get('title', 'N/A')
        description = interest.get('description', 'N/A')
        
        content = f"""
Filosof√≠a e Intereses:

{title}:
{description}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "philosophy",
                "title": title,
                "source": "portfolio.yaml"
            }
        ))
    
    # 10. Contexto del chatbot (personalidad)
    chatbot_context = data.get('chatbot_context', {})
    if chatbot_context:
        personality = chatbot_context.get('personality', 'N/A')
        tone = chatbot_context.get('tone', 'N/A')
        expertise_areas = ', '.join(chatbot_context.get('expertise_areas', []))
        
        content = f"""
Personalidad del Profesional:

Personalidad: {personality}
Tono de comunicaci√≥n: {tone}
√Åreas de expertise: {expertise_areas}
"""
        documents.append(Document(
            page_content=content.strip(),
            metadata={
                "type": "personality",
                "source": "portfolio.yaml"
            }
        ))
    
    # Crear chunks sem√°nticos con overlap para mejor retrieval
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,  # Tama√±o √≥ptimo para embeddings
        chunk_overlap=50,  # Overlap para mantener contexto
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""]
    )
    
    chunks = text_splitter.split_documents(documents)
    
    return chunks


def save_chunks_summary(chunks: List[Document], output_path: str = "data/chunks_summary.txt"):
    """
    Guarda un resumen de los chunks generados para inspecci√≥n.
    
    Args:
        chunks: Lista de documentos chunk
        output_path: Ruta donde guardar el resumen
    """
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"Total de chunks generados: {len(chunks)}\n\n")
        f.write("=" * 80 + "\n\n")
        
        for i, chunk in enumerate(chunks, 1):
            f.write(f"CHUNK #{i}\n")
            f.write(f"Metadata: {chunk.metadata}\n")
            f.write(f"Content:\n{chunk.page_content}\n")
            f.write("=" * 80 + "\n\n")
    
    print(f"‚úì Resumen guardado en: {output_path}")


if __name__ == "__main__":
    # Test del script
    portfolio_path = "data/portfolio.yaml"
    
    if not Path(portfolio_path).exists():
        print(f"‚ùå Error: No se encontr√≥ {portfolio_path}")
        exit(1)
    
    print(f"üìÑ Procesando {portfolio_path}...")
    chunks = process_portfolio_to_chunks(portfolio_path)
    
    print(f"‚úì {len(chunks)} chunks generados")
    
    # Mostrar estad√≠sticas
    types = {}
    for chunk in chunks:
        chunk_type = chunk.metadata.get('type', 'unknown')
        types[chunk_type] = types.get(chunk_type, 0) + 1
    
    print("\nüìä Distribuci√≥n por tipo:")
    for chunk_type, count in sorted(types.items()):
        print(f"  - {chunk_type}: {count} chunks")
    
    # Guardar resumen
    save_chunks_summary(chunks)
    print("\n‚úÖ Preparaci√≥n de datos completada")

