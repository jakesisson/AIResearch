{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2e74b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain[groq] langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7522473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opentelemetry-api in c:\\users\\parth\\appdata\\roaming\\python\\python312\\site-packages (1.37.0)\n",
      "Requirement already satisfied: langchain-chroma in c:\\users\\parth\\appdata\\roaming\\python\\python312\\site-packages (0.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement chromadbpip (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for chromadbpip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade opentelemetry-api langchain-chroma chromadbpip install -U opentelemetry-api opentelemetry-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04678c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "from modules.document_processor import DocumentProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42221159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8ddef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chapter', 'verse', 'speaker', 'sanskrit', 'translation', 'question']\n",
      "Original CSV had 700 rows.\n",
      "Processed into 117 final document chunks.\n",
      "\n",
      "--- Example of the First Chunk ---\n",
      "Content:\n",
      "Chapter 1 Verse 1 — Dhritarashtra said, \"What did my people and the sons of Pandu do when they had assembled together, eager for battle, on the holy plain of Kurukshetra, O Sanjaya?\"\n",
      "\n",
      "Chapter 1 Verse 2 — Sanjaya said: Having seen the army of the Pandavas drawn up in battle array, King Duryodhana approached his teacher, Drona, and spoke these words.\n",
      "\n",
      "Chapter 1 Verse 3 — Behold, O Teacher! This mighty army of the sons of Pandu, arrayed by the son of Drupada, thy wise disciple.\n",
      "\n",
      "Chapter 1 Verse 4 — Here are heroes, mighty archers, equal in battle to Bhima and Arjuna, Yuyudhana (Satyaki), Virata, and Drupada—all mighty warriors.\n",
      "\n",
      "Chapter 1 Verse 5 — Dhrishtaketu, Chekitana, the valiant king of Kasi, Purujit, Kuntibhoja, and Saibya—the best of men.\n",
      "\n",
      "Chapter 1 Verse 6 — The strong Yudhamanyu and the brave Uttamaujas, the son of Subhadra (Abhimanyu, the son of Subhadra and Arjuna), and the sons of Draupadi, all of them great charioteers (great heroes).\"\n",
      "\n",
      "Metadata:\n",
      "{'row_start': 0, 'row_end': 5, 'filename': 'gita.csv', 'chapters': [1, 1, 1, 1, 1, 1], 'verses': [1, 2, 3, 4, 5, 6]}\n",
      "------------------------------\n",
      "\n",
      "--- Example of the Second Chunk ---\n",
      "Content:\n",
      "Chapter 1 Verse 7 — Know also, O best among the twice-born! the names of those who are the most distinguished amongst ourselves, the leaders of my army; these I name to you for your information.\n",
      "\n",
      "Chapter 1 Verse 8 — \"Thou thyself, Bhishma, Karna, Kripa, the victorious in war, Asvatthama, Vikarna, and Bhurisrava, the son of Somadatta—all these are ready for battle.\"\n",
      "\n",
      "Chapter 1 Verse 9 — And also many other heroes, ready to give up their lives for my sake, armed with various weapons and missiles, all well-skilled in battle.\n",
      "\n",
      "Chapter 1 Verse 10 — Our army, marshalled by Bhishma, is insufficient, whereas theirs, marshalled by Bhima, is sufficient.\n",
      "\n",
      "Chapter 1 Verse 11 — Therefore, do all of you, stationed in your respective positions in the several divisions of the army, protect Bhishma alone.\n",
      "\n",
      "Chapter 1 Verse 12 — His glorious grandsire, the oldest of the Kauravas, roared like a lion to cheer Duryodhana and blew his conch.\n",
      "\n",
      "Metadata:\n",
      "{'row_start': 6, 'row_end': 11, 'filename': 'gita.csv', 'chapters': [1, 1, 1, 1, 1, 1], 'verses': [7, 8, 9, 10, 11, 12]}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "from modules.document_processor import DocumentProcessor\n",
    " \n",
    "with open(\"gita.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    csv_buffer = io.StringIO(f.read())\n",
    "\n",
    "processor = DocumentProcessor()\n",
    "final_docs, original_df = processor.process_csv_to_chunks(\n",
    "    file_path=csv_buffer,          # now it's actual CSV content\n",
    "    content_column=\"translation\",\n",
    "    filename=\"gita.csv\"            # required if file_path is not a path\n",
    ")\n",
    "\n",
    "print(pd.read_csv(\"gita.csv\", nrows=0).columns.tolist())\n",
    "\n",
    "\n",
    "# --- 3. Inspect the Results ---\n",
    "print(f\"Original CSV had {len(original_df)} rows.\")\n",
    "print(f\"Processed into {len(final_docs)} final document chunks.\\n\")\n",
    "\n",
    "# Print the first chunk to see the result\n",
    "print(\"--- Example of the First Chunk ---\")\n",
    "print(f\"Content:\\n{final_docs[0].page_content}\")\n",
    "print(f\"\\nMetadata:\\n{final_docs[0].metadata}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Print the second chunk to see another example\n",
    "if len(final_docs) > 1:\n",
    "    print(\"\\n--- Example of the Second Chunk ---\")\n",
    "    print(f\"Content:\\n{final_docs[1].page_content}\")\n",
    "    print(f\"\\nMetadata:\\n{final_docs[1].metadata}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6bc9b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 185 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(final_docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5a45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the document processor.\"\"\"\n",
    "    CHUNK_SIZE = 1000  # The target size for each final text chunk in characters.\n",
    "    CHUNK_OVERLAP = 150 # Number of characters to overlap between chunks.\n",
    "    GROUP_SIZE = 5     # Number of CSV rows to group together before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f574b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4ecde6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\AppData\\Local\\Temp\\ipykernel_19320\\3056763568.py:14: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported Chroma and initialized HuggingFace embeddings.\n",
      "Successfully created Chroma vector store instance with HuggingFace embeddings.\n",
      "Successfully added documents to the vector store.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "# from langchain_openai import OpenAIEmbeddings # <- REMOVE THIS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings # <- ADD THIS\n",
    "\n",
    "# 1. Initialize your new embedding function\n",
    "# embeddings = OpenAIEmbeddings() # <- REPLACE THIS\n",
    "\n",
    "# Use a popular, lightweight model from Hugging Face\n",
    "# The first time you run this, it will download the model which may take a minute.\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'} # Use 'cuda' for GPU\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "print(\"Successfully imported Chroma and initialized HuggingFace embeddings.\")\n",
    "\n",
    "# 2. Your code to create or load the vector store\n",
    "# THIS PART REMAINS EXACTLY THE SAME\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_huggingface_db\", # Changed directory to avoid conflicts\n",
    ")\n",
    "\n",
    "print(\"Successfully created Chroma vector store instance with HuggingFace embeddings.\")\n",
    "\n",
    "# 3. Add some documents to verify it's working\n",
    "vector_store.add_texts(\n",
    "    texts=[\"This is a test document about ChromaDB.\", \"LangChain helps build LLM applications.\"],\n",
    "    metadatas=[{\"source\": \"test1\"}, {\"source\": \"test2\"}],\n",
    "    ids=[\"doc1\", \"doc2\"]\n",
    ")\n",
    "\n",
    "print(\"Successfully added documents to the vector store.\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "241f3fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes. Certain times of day—especially early morning (dawn) and twilight—are regarded as most auspicious for yoga practice, and regular, sustained practice over time is essential for progress.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "# Assume 'vector_store' and 'query' are already defined from the retrieval step\n",
    "# vector_store = Chroma(...)\n",
    "\n",
    "# --- Groq Integration ---\n",
    "\n",
    "# Make sure your Groq API key is set\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"gsk_...\"\n",
    "query = \"Is there any significance of time in the attainment of Yoga?\"\n",
    "retrieved_docs = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "# 1. Define the Groq LLM you want to use for generation\n",
    "# Llama3 8b is a great, fast choice available on Groq\n",
    "llm = ChatGroq(model_name=\"openai/gpt-oss-20b\")\n",
    "\n",
    "# 2. Create a prompt template (this part is unchanged)\n",
    "prompt_template = \"\"\"\n",
    "\"You are a helpful assistant. Use the provided context from the source\"\n",
    "             \"the user's question accurately. \"\n",
    "             \"Do not include verse text in your answer. The answer is is ashort as possible.\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# 3. Format the retrieved documents into a single context string\n",
    "context_string = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# 4. Fill the prompt with the context and question\n",
    "formatted_prompt = prompt_template.format(\n",
    "    context=context_string,\n",
    "    question=query\n",
    ")\n",
    "\n",
    "# 5. Call the Groq LLM to get the fast, final answer\n",
    "final_answer = llm.invoke(formatted_prompt)\n",
    "\n",
    " \n",
    "print(final_answer.content)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9db49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f4027d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma + HuggingFaceEmbeddings ready.\n"
     ]
    }
   ],
   "source": [
    "# Notebook cell: setup embeddings and Chroma (no OpenAI)\n",
    "from modules.config import Config\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# HuggingFace embeddings (same as Neo4j pipeline)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=Config.EMBEDDING_MODEL,\n",
    "    model_kwargs={'device': Config.EMBEDDING_DEVICE},\n",
    "    encode_kwargs={'normalize_embeddings': True},\n",
    ")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"gita_idx\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_huggingface_db\",\n",
    ")\n",
    "print(\"Chroma + HuggingFaceEmbeddings ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ddfba8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected metadata value to be a str, int, float, bool, SparseVector, or None, got [1, 1, 1, 1, 1, 1] which is a list in upsert.\n\nTry filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_chroma\\vectorstores.py:647\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\chromadb\\api\\models\\Collection.py:442\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m upsert_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_prepare_upsert_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_upsert(\n\u001b[0;32m    452\u001b[0m     collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    453\u001b[0m     ids\u001b[38;5;241m=\u001b[39mupsert_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    459\u001b[0m     database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[0;32m    460\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:95\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:417\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_upsert_request\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m \u001b[43mvalidate_insert_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# Prepare\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\chromadb\\api\\types.py:317\u001b[0m, in \u001b[0;36mvalidate_insert_record_set\u001b[1;34m(record_set)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadatas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[43mvalidate_metadatas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadatas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\chromadb\\api\\types.py:899\u001b[0m, in \u001b[0;36mvalidate_metadatas\u001b[1;34m(metadatas)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m metadatas:\n\u001b[1;32m--> 899\u001b[0m     \u001b[43mvalidate_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadatas\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\chromadb\\api\\types.py:859\u001b[0m, in \u001b[0;36mvalidate_metadata\u001b[1;34m(metadata)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    857\u001b[0m         value, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    858\u001b[0m     ):\n\u001b[1;32m--> 859\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    860\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be a str, int, float, bool, SparseVector, or None, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    861\u001b[0m         )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "\u001b[1;31mValueError\u001b[0m: Expected metadata value to be a str, int, float, bool, SparseVector, or None, got [1, 1, 1, 1, 1, 1] which is a list in upsert.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m final_docs, original_df \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mprocess_csv_to_chunks(\n\u001b[0;32m      7\u001b[0m     file_path\u001b[38;5;241m=\u001b[39mcsv_path,\n\u001b[0;32m      8\u001b[0m     content_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgita.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Populate Chroma with the same docs\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChroma populated with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(final_docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chunks from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\vectorstores\\base.py:279\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[1;34m(self, documents, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    278\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_chroma\\vectorstores.py:659\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[0;32m    655\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry filtering complex metadata from the document using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    657\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_community.vectorstores.utils.filter_complex_metadata.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    658\u001b[0m             )\n\u001b[1;32m--> 659\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    660\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m empty_ids:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected metadata value to be a str, int, float, bool, SparseVector, or None, got [1, 1, 1, 1, 1, 1] which is a list in upsert.\n\nTry filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata."
     ]
    }
   ],
   "source": [
    "# Notebook cell: build docs for Chroma (if not already built in this session)\n",
    "from modules.document_processor import DocumentProcessor\n",
    "\n",
    "csv_path = \"gita.csv\"  # adjust path if needed\n",
    "processor = DocumentProcessor()\n",
    "final_docs, original_df = processor.process_csv_to_chunks(\n",
    "    file_path=csv_path,\n",
    "    content_column=\"translation\",\n",
    "    filename=\"gita.csv\"\n",
    ")\n",
    "\n",
    "# Populate Chroma with the same docs\n",
    "vector_store.add_documents(final_docs)\n",
    "print(f\"Chroma populated with {len(final_docs)} chunks from {csv_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook cell: compare function\n",
    "from modules.llm_chain import LLMChain\n",
    "from modules.neo4j_manager import Neo4jManager\n",
    "from modules.config import Config\n",
    "\n",
    "def compare_results(query: str, filename: str, top_k: int = 5):\n",
    "    llm = LLMChain()\n",
    "\n",
    "    # 1) Rewrite once for fairness (same rule as your app)\n",
    "    rw = llm.rewrite_query(query, chat_history=[], source_name=filename, fallback_on_error=True)\n",
    "    rewritten = rw.get(\"rewritten_query\", query)\n",
    "\n",
    "    # 2) Neo4j retrieval (connect to existing index for this file)\n",
    "    idx_name = Config.get_index_name(filename)\n",
    "    neo = Neo4jManager()                            # uses the same HF embeddings as Chroma\n",
    "    neo.connect_to_existing_index(idx_name)         # index should already exist (created via app)\n",
    "    neo_docs = neo.retrieve_with_filename_filter(rewritten, filename, top_k=top_k)\n",
    "    neo_answer = llm.graph_qa_chain(\n",
    "        question=query, docs=neo_docs, source_name=filename, memory_context=None, fallback_on_error=True\n",
    "    )\n",
    "\n",
    "    # 3) Chroma retrieval with the SAME rewritten query and SAME LLM\n",
    "    chroma_docs = vector_store.similarity_search(rewritten, k=top_k)\n",
    "    chroma_answer = llm.graph_qa_chain(\n",
    "        question=query, docs=chroma_docs, source_name=filename, memory_context=None, fallback_on_error=True\n",
    "    )\n",
    "\n",
    "    # 4) Print side-by-side summaries\n",
    "    print(\"=== Query ===\")\n",
    "    print(\"Original: \", query)\n",
    "    print(\"Rewritten:\", rewritten)\n",
    "    print()\n",
    "\n",
    "    print(\"=== Neo4j Answer ===\")\n",
    "    print(neo_answer.get(\"text\", \"\"))\n",
    "    print(\"Refs:\", neo_answer.get(\"refrence\", []))\n",
    "    print()\n",
    "\n",
    "    print(\"=== Chroma Answer ===\")\n",
    "    print(chroma_answer.get(\"text\", \"\"))\n",
    "    print(\"Refs:\", chroma_answer.get(\"refrence\", []))\n",
    "    print()\n",
    "\n",
    "    # Optional: top-1 snippet previews to see retrieved context difference\n",
    "    if neo_docs:\n",
    "        print(\"Neo4j top-1 snippet:\", neo_docs[0].page_content[:250].replace(\"\\n\", \" \"), \"| score:\", neo_docs[0].metadata.get(\"score\"))\n",
    "    if chroma_docs:\n",
    "        print(\"Chroma top-1 snippet:\", chroma_docs[0].page_content[:250].replace(\"\\n\", \" \"))\n",
    "\n",
    "# Example usage:\n",
    "# compare_results(\"What is karma yoga?\", filename=\"gita.csv\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5728302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Neo4j vector index from the same final_docs (one-time)\n",
    "nm = Neo4jManager()\n",
    "nm.create_vector_store(final_docs, Config.get_index_name(\"gita.csv\"))\n",
    "nm.create_file_relationships(\"gita.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0519509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
