{
  "project": "Research Data/AI-Product-Analyzer",
  "repo": "Yaswanth-Mitta/multi",
  "prior_commit": "cfe471701dd29b6c354874ad9015bf8957dc69b5",
  "researched_commit": "6779ffda3a8a21dec8afb5b57bfee345a8a19798",
  "compare_url": "https://github.com/Yaswanth-Mitta/AI-Product-Analyzer/compare/cfe471701dd29b6c354874ad9015bf8957dc69b5...6779ffda3a8a21dec8afb5b57bfee345a8a19798",
  "ahead_by": 1,
  "behind_by": 0,
  "changed_files": [
    {
      "path": "agent/research_agent/langchain_service.py",
      "status": "modified",
      "additions": 34,
      "deletions": 34,
      "patch": "@@ -37,9 +37,9 @@ def process_scraped_data(self, scraped_data: List[Dict[str, Any]]) -> str:\n             # Combine chunks into structured format\n             structured_content = \"\"\n             for i, chunk in enumerate(chunks[:5]):  # Limit to 5 chunks\n-                structured_content += f\"\\\\n--- Source {i+1}: {chunk.metadata['title']} ---\\\\n\"\n-                structured_content += f\"URL: {chunk.metadata['source']}\\\\n\"\n-                structured_content += f\"Content: {chunk.page_content}\\\\n\"\n+                structured_content += f\"\\n--- Source {i+1}: {chunk.metadata['title']} ---\\n\"\n+                structured_content += f\"URL: {chunk.metadata['source']}\\n\"\n+                structured_content += f\"Content: {chunk.page_content}\\n\"\n             \n             return structured_content\n             \n@@ -50,13 +50,13 @@ def process_scraped_data(self, scraped_data: List[Dict[str, Any]]) -> str:\n     def process_youtube_data(self, youtube_reviews: List[Dict[str, Any]]) -> str:\n         \"\"\"Process YouTube review data with enhanced content extraction\"\"\"\n         try:\n-            youtube_content = \"\\\\n=== YOUTUBE REVIEW ANALYSIS (10 Videos) ===\\\\n\"\n+            youtube_content = \"\\n=== YOUTUBE REVIEW ANALYSIS (10 Videos) ===\\n\"\n             \n             for i, video in enumerate(youtube_reviews, 1):\n-                youtube_content += f\"\\\\n--- Video {i}/10 ---\\\\n\"\n-                youtube_content += f\"Title: {video['title']}\\\\n\"\n-                youtube_content += f\"Views: {video['views']}\\\\n\"\n-                youtube_content += f\"URL: {video['url']}\\\\n\"\n+                youtube_content += f\"\\n--- Video {i}/10 ---\\n\"\n+                youtube_content += f\"Title: {video['title']}\\n\"\n+                youtube_content += f\"Views: {video['views']}\\n\"\n+                youtube_content += f\"URL: {video['url']}\\n\"\n                 \n                 if 'transcript' in video and video['transcript'] and len(video['transcript']) > 20:\n                     # Process meaningful transcript content\n@@ -69,65 +69,65 @@ def process_youtube_data(self, youtube_reviews: List[Dict[str, Any]]) -> str:\n                     if chunks:\n                         # Extract key insights from transcript\n                         content = chunks[0].page_content\n-                        youtube_content += f\"Review Content: {content[:400]}\\\\n\"\n+                        youtube_content += f\"Review Content: {content[:400]}\\n\"\n                         \n                         # Add analysis points\n                         if 'pros' in content.lower() or 'cons' in content.lower():\n-                            youtube_content += \"Analysis: Contains pros/cons discussion\\\\n\"\n+                            youtube_content += \"Analysis: Contains pros/cons discussion\\n\"\n                         if 'camera' in content.lower():\n-                            youtube_content += \"Analysis: Includes camera review\\\\n\"\n+                            youtube_content += \"Analysis: Includes camera review\\n\"\n                         if 'battery' in content.lower():\n-                            youtube_content += \"Analysis: Covers battery performance\\\\n\"\n+                            youtube_content += \"Analysis: Covers battery performance\\n\"\n                         if 'performance' in content.lower():\n-                            youtube_content += \"Analysis: Discusses performance metrics\\\\n\"\n+                            youtube_content += \"Analysis: Discusses performance metrics\\n\"\n                 else:\n-                    youtube_content += \"Review Content: Professional video review with visual demonstrations and expert analysis\\\\n\"\n+                    youtube_content += \"Review Content: Professional video review with visual demonstrations and expert analysis\\n\"\n                 \n-                youtube_content += \"\\\\n\"\n+                youtube_content += \"\\n\"\n             \n-            youtube_content += f\"\\\\nTotal YouTube Reviews Analyzed: {len(youtube_reviews)}\\\\n\"\n+            youtube_content += f\"\\nTotal YouTube Reviews Analyzed: {len(youtube_reviews)}\\n\"\n             return youtube_content\n             \n         except Exception as e:\n             print(f\"YouTube data processing failed: {e}\")\n-            return \"=== YOUTUBE REVIEW ANALYSIS ===\\\\nFailed to process YouTube review data\"\n+            return \"=== YOUTUBE REVIEW ANALYSIS ===\\nFailed to process YouTube review data\"\n     \n     def create_comprehensive_context(self, search_results: List[Dict], scraped_data: List[Dict], \n                                    youtube_reviews: List[Dict], reddit_posts: List[Dict]) -> str:\n         \"\"\"Create comprehensive context using all data sources with enhanced processing\"\"\"\n         \n-        context = \"=== COMPREHENSIVE PRODUCT REVIEW DATA ===\\\\n\\\\n\"\n+        context = \"=== COMPREHENSIVE PRODUCT REVIEW DATA ===\\n\\n\"\n         \n         # Add data source summary\n-        context += f\"DATA SOURCES ANALYZED:\\\\n\"\n-        context += f\"- Web Reviews: {len(scraped_data)} sites scraped\\\\n\"\n-        context += f\"- YouTube Reviews: {len(youtube_reviews)} videos analyzed\\\\n\"\n-        context += f\"- Search Results: {len(search_results)} results processed\\\\n\\\\n\"\n+        context += f\"DATA SOURCES ANALYZED:\\n\"\n+        context += f\"- Web Reviews: {len(scraped_data)} sites scraped\\n\"\n+        context += f\"- YouTube Reviews: {len(youtube_reviews)} videos analyzed\\n\"\n+        context += f\"- Search Results: {len(search_results)} results processed\\n\\n\"\n         \n         # Process web scraping data with enhanced analysis\n         web_content = self.process_scraped_data(scraped_data)\n-        context += f\"=== WEB REVIEW CONTENT ===\\\\n{web_content}\\\\n\"\n+        context += f\"=== WEB REVIEW CONTENT ===\\n{web_content}\\n\"\n         \n         # Process YouTube data with detailed analysis\n         if youtube_reviews:\n             youtube_content = self.process_youtube_data(youtube_reviews)\n-            context += f\"\\\\n{youtube_content}\\\\n\"\n+            context += f\"\\n{youtube_content}\\n\"\n         else:\n-            context += \"\\\\n=== YOUTUBE REVIEWS ===\\\\nNo YouTube reviews processed\\\\n\\\\n\"\n+            context += \"\\n=== YOUTUBE REVIEWS ===\\nNo YouTube reviews processed\\n\\n\"\n         \n         # Add search result summaries with enhanced metadata\n-        context += \"\\\\n=== SEARCH RESULT SUMMARIES ===\\\\n\"\n+        context += \"\\n=== SEARCH RESULT SUMMARIES ===\\n\"\n         for i, result in enumerate(search_results, 1):\n-            context += f\"{i}. {result['title']}\\\\n\"\n-            context += f\"   Source: {result.get('source', 'Web')}\\\\n\"\n-            context += f\"   Summary: {result['snippet']}\\\\n\"\n-            context += f\"   URL: {result['link']}\\\\n\\\\n\"\n+            context += f\"{i}. {result['title']}\\n\"\n+            context += f\"   Source: {result.get('source', 'Web')}\\n\"\n+            context += f\"   Summary: {result['snippet']}\\n\"\n+            context += f\"   URL: {result['link']}\\n\\n\"\n         \n         # Add analysis summary\n-        context += \"\\\\n=== DATA QUALITY ASSESSMENT ===\\\\n\"\n+        context += \"\\n=== DATA QUALITY ASSESSMENT ===\\n\"\n         total_content = len([d for d in scraped_data if d.get('scraped', False)])\n-        context += f\"Successfully scraped content from {total_content} sources\\\\n\"\n-        context += f\"YouTube analysis covers {len(youtube_reviews)} professional reviews\\\\n\"\n-        context += f\"Search results provide {len(search_results)} additional data points\\\\n\"\n+        context += f\"Successfully scraped content from {total_content} sources\\n\"\n+        context += f\"YouTube analysis covers {len(youtube_reviews)} professional reviews\\n\"\n+        context += f\"Search results provide {len(search_results)} additional data points\\n\"\n         \n         return context\n\\ No newline at end of file",
      "patch_lines": [
        "@@ -37,9 +37,9 @@ def process_scraped_data(self, scraped_data: List[Dict[str, Any]]) -> str:\n",
        "             # Combine chunks into structured format\n",
        "             structured_content = \"\"\n",
        "             for i, chunk in enumerate(chunks[:5]):  # Limit to 5 chunks\n",
        "-                structured_content += f\"\\\\n--- Source {i+1}: {chunk.metadata['title']} ---\\\\n\"\n",
        "-                structured_content += f\"URL: {chunk.metadata['source']}\\\\n\"\n",
        "-                structured_content += f\"Content: {chunk.page_content}\\\\n\"\n",
        "+                structured_content += f\"\\n--- Source {i+1}: {chunk.metadata['title']} ---\\n\"\n",
        "+                structured_content += f\"URL: {chunk.metadata['source']}\\n\"\n",
        "+                structured_content += f\"Content: {chunk.page_content}\\n\"\n",
        "             \n",
        "             return structured_content\n",
        "             \n",
        "@@ -50,13 +50,13 @@ def process_scraped_data(self, scraped_data: List[Dict[str, Any]]) -> str:\n",
        "     def process_youtube_data(self, youtube_reviews: List[Dict[str, Any]]) -> str:\n",
        "         \"\"\"Process YouTube review data with enhanced content extraction\"\"\"\n",
        "         try:\n",
        "-            youtube_content = \"\\\\n=== YOUTUBE REVIEW ANALYSIS (10 Videos) ===\\\\n\"\n",
        "+            youtube_content = \"\\n=== YOUTUBE REVIEW ANALYSIS (10 Videos) ===\\n\"\n",
        "             \n",
        "             for i, video in enumerate(youtube_reviews, 1):\n",
        "-                youtube_content += f\"\\\\n--- Video {i}/10 ---\\\\n\"\n",
        "-                youtube_content += f\"Title: {video['title']}\\\\n\"\n",
        "-                youtube_content += f\"Views: {video['views']}\\\\n\"\n",
        "-                youtube_content += f\"URL: {video['url']}\\\\n\"\n",
        "+                youtube_content += f\"\\n--- Video {i}/10 ---\\n\"\n",
        "+                youtube_content += f\"Title: {video['title']}\\n\"\n",
        "+                youtube_content += f\"Views: {video['views']}\\n\"\n",
        "+                youtube_content += f\"URL: {video['url']}\\n\"\n",
        "                 \n",
        "                 if 'transcript' in video and video['transcript'] and len(video['transcript']) > 20:\n",
        "                     # Process meaningful transcript content\n",
        "@@ -69,65 +69,65 @@ def process_youtube_data(self, youtube_reviews: List[Dict[str, Any]]) -> str:\n",
        "                     if chunks:\n",
        "                         # Extract key insights from transcript\n",
        "                         content = chunks[0].page_content\n",
        "-                        youtube_content += f\"Review Content: {content[:400]}\\\\n\"\n",
        "+                        youtube_content += f\"Review Content: {content[:400]}\\n\"\n",
        "                         \n",
        "                         # Add analysis points\n",
        "                         if 'pros' in content.lower() or 'cons' in content.lower():\n",
        "-                            youtube_content += \"Analysis: Contains pros/cons discussion\\\\n\"\n",
        "+                            youtube_content += \"Analysis: Contains pros/cons discussion\\n\"\n",
        "                         if 'camera' in content.lower():\n",
        "-                            youtube_content += \"Analysis: Includes camera review\\\\n\"\n",
        "+                            youtube_content += \"Analysis: Includes camera review\\n\"\n",
        "                         if 'battery' in content.lower():\n",
        "-                            youtube_content += \"Analysis: Covers battery performance\\\\n\"\n",
        "+                            youtube_content += \"Analysis: Covers battery performance\\n\"\n",
        "                         if 'performance' in content.lower():\n",
        "-                            youtube_content += \"Analysis: Discusses performance metrics\\\\n\"\n",
        "+                            youtube_content += \"Analysis: Discusses performance metrics\\n\"\n",
        "                 else:\n",
        "-                    youtube_content += \"Review Content: Professional video review with visual demonstrations and expert analysis\\\\n\"\n",
        "+                    youtube_content += \"Review Content: Professional video review with visual demonstrations and expert analysis\\n\"\n",
        "                 \n",
        "-                youtube_content += \"\\\\n\"\n",
        "+                youtube_content += \"\\n\"\n",
        "             \n",
        "-            youtube_content += f\"\\\\nTotal YouTube Reviews Analyzed: {len(youtube_reviews)}\\\\n\"\n",
        "+            youtube_content += f\"\\nTotal YouTube Reviews Analyzed: {len(youtube_reviews)}\\n\"\n",
        "             return youtube_content\n",
        "             \n",
        "         except Exception as e:\n",
        "             print(f\"YouTube data processing failed: {e}\")\n",
        "-            return \"=== YOUTUBE REVIEW ANALYSIS ===\\\\nFailed to process YouTube review data\"\n",
        "+            return \"=== YOUTUBE REVIEW ANALYSIS ===\\nFailed to process YouTube review data\"\n",
        "     \n",
        "     def create_comprehensive_context(self, search_results: List[Dict], scraped_data: List[Dict], \n",
        "                                    youtube_reviews: List[Dict], reddit_posts: List[Dict]) -> str:\n",
        "         \"\"\"Create comprehensive context using all data sources with enhanced processing\"\"\"\n",
        "         \n",
        "-        context = \"=== COMPREHENSIVE PRODUCT REVIEW DATA ===\\\\n\\\\n\"\n",
        "+        context = \"=== COMPREHENSIVE PRODUCT REVIEW DATA ===\\n\\n\"\n",
        "         \n",
        "         # Add data source summary\n",
        "-        context += f\"DATA SOURCES ANALYZED:\\\\n\"\n",
        "-        context += f\"- Web Reviews: {len(scraped_data)} sites scraped\\\\n\"\n",
        "-        context += f\"- YouTube Reviews: {len(youtube_reviews)} videos analyzed\\\\n\"\n",
        "-        context += f\"- Search Results: {len(search_results)} results processed\\\\n\\\\n\"\n",
        "+        context += f\"DATA SOURCES ANALYZED:\\n\"\n",
        "+        context += f\"- Web Reviews: {len(scraped_data)} sites scraped\\n\"\n",
        "+        context += f\"- YouTube Reviews: {len(youtube_reviews)} videos analyzed\\n\"\n",
        "+        context += f\"- Search Results: {len(search_results)} results processed\\n\\n\"\n",
        "         \n",
        "         # Process web scraping data with enhanced analysis\n",
        "         web_content = self.process_scraped_data(scraped_data)\n",
        "-        context += f\"=== WEB REVIEW CONTENT ===\\\\n{web_content}\\\\n\"\n",
        "+        context += f\"=== WEB REVIEW CONTENT ===\\n{web_content}\\n\"\n",
        "         \n",
        "         # Process YouTube data with detailed analysis\n",
        "         if youtube_reviews:\n",
        "             youtube_content = self.process_youtube_data(youtube_reviews)\n",
        "-            context += f\"\\\\n{youtube_content}\\\\n\"\n",
        "+            context += f\"\\n{youtube_content}\\n\"\n",
        "         else:\n",
        "-            context += \"\\\\n=== YOUTUBE REVIEWS ===\\\\nNo YouTube reviews processed\\\\n\\\\n\"\n",
        "+            context += \"\\n=== YOUTUBE REVIEWS ===\\nNo YouTube reviews processed\\n\\n\"\n",
        "         \n",
        "         # Add search result summaries with enhanced metadata\n",
        "-        context += \"\\\\n=== SEARCH RESULT SUMMARIES ===\\\\n\"\n",
        "+        context += \"\\n=== SEARCH RESULT SUMMARIES ===\\n\"\n",
        "         for i, result in enumerate(search_results, 1):\n",
        "-            context += f\"{i}. {result['title']}\\\\n\"\n",
        "-            context += f\"   Source: {result.get('source', 'Web')}\\\\n\"\n",
        "-            context += f\"   Summary: {result['snippet']}\\\\n\"\n",
        "-            context += f\"   URL: {result['link']}\\\\n\\\\n\"\n",
        "+            context += f\"{i}. {result['title']}\\n\"\n",
        "+            context += f\"   Source: {result.get('source', 'Web')}\\n\"\n",
        "+            context += f\"   Summary: {result['snippet']}\\n\"\n",
        "+            context += f\"   URL: {result['link']}\\n\\n\"\n",
        "         \n",
        "         # Add analysis summary\n",
        "-        context += \"\\\\n=== DATA QUALITY ASSESSMENT ===\\\\n\"\n",
        "+        context += \"\\n=== DATA QUALITY ASSESSMENT ===\\n\"\n",
        "         total_content = len([d for d in scraped_data if d.get('scraped', False)])\n",
        "-        context += f\"Successfully scraped content from {total_content} sources\\\\n\"\n",
        "-        context += f\"YouTube analysis covers {len(youtube_reviews)} professional reviews\\\\n\"\n",
        "-        context += f\"Search results provide {len(search_results)} additional data points\\\\n\"\n",
        "+        context += f\"Successfully scraped content from {total_content} sources\\n\"\n",
        "+        context += f\"YouTube analysis covers {len(youtube_reviews)} professional reviews\\n\"\n",
        "+        context += f\"Search results provide {len(search_results)} additional data points\\n\"\n",
        "         \n",
        "         return context\n",
        "\\ No newline at end of file\n"
      ]
    },
    {
      "path": "agent/research_agent/orchestrator.py",
      "status": "modified",
      "additions": 37,
      "deletions": 16,
      "patch": "@@ -112,23 +112,35 @@ def _is_new_research_query(self, query: str) -> bool:\n         query_lower = query.lower()\n         \n         # Keywords that clearly indicate follow-up questions\n-        followup_keywords = ['camera', 'battery', 'price', 'color', 'colors', 'screen', 'display', \n-                           'performance', 'storage', 'memory', 'size', 'weight', 'features',\n-                           'what', 'how', 'when', 'where', 'why', 'is it', 'does it', 'can it',\n-                           'details', 'detail', 'about', 'specs', 'specification']\n+        followup_keywords = [\n+            'camera', 'battery', 'price', 'color', 'colors', 'screen', 'display', \n+            'performance', 'storage', 'memory', 'size', 'weight', 'features',\n+            'what', 'how', 'when', 'where', 'why', 'is it', 'does it', 'can it',\n+            'details', 'detail', 'about', 'specs', 'specification', 'tell me',\n+            'more about', 'explain', 'describe', 'show me', 'good', 'bad',\n+            'pros', 'cons', 'worth', 'buy', 'purchase', 'recommend'\n+        ]\n+        \n+        # Short queries are likely follow-ups\n+        if len(query.split()) <= 3:\n+            return False\n         \n         # If it's clearly a follow-up question\n         if any(keyword in query_lower for keyword in followup_keywords):\n             return False\n         \n         # Keywords that indicate new research\n-        new_research_keywords = ['review of', 'analysis of', 'compare with']\n+        new_research_keywords = ['review of', 'analysis of', 'compare', 'vs', 'versus']\n         \n         # If query contains completely different product names\n         if self.memory.current_session:\n             current_product = self.memory.current_session['product'].lower()\n-            different_products = ['iphone', 'samsung', 'oneplus', 'xiaomi', 'huawei', 'sony', 'lg']\n-            if any(product in query_lower for product in different_products) and not any(word in current_product for word in query_lower.split()):\n+            # Check if query mentions a completely different product\n+            product_brands = ['iphone', 'samsung', 'oneplus', 'xiaomi', 'huawei', 'sony', 'lg', 'pixel', 'galaxy']\n+            mentioned_products = [p for p in product_brands if p in query_lower]\n+            current_products = [p for p in product_brands if p in current_product]\n+            \n+            if mentioned_products and current_products and not any(p in current_products for p in mentioned_products):\n                 return True\n         \n         # If it contains explicit new research keywords\n@@ -143,18 +155,20 @@ def _handle_followup_query(self, query: str) -> str:\n         \n         # Create focused prompt for follow-up\n         followup_prompt = f\"\"\"\n-        You are answering a follow-up question about {self.memory.current_session['product']} using previously researched data.\n+        You are a product expert answering a follow-up question about {self.memory.current_session['product']}.\n         \n-        QUESTION: {query}\n+        USER QUESTION: {query}\n         \n-        RESEARCH DATA:\n+        AVAILABLE RESEARCH DATA:\n         {research_context}\n         \n         INSTRUCTIONS:\n-        - Answer the specific question using the research data\n-        - Be concise and direct\n-        - Reference specific details from the research when relevant\n-        - If the question can't be answered from the data, say so\n+        - Answer the specific question using the research data provided\n+        - Be detailed and informative while staying focused on the question\n+        - Reference specific details from reviews, specs, or user feedback when relevant\n+        - If the exact information isn't in the data, provide the closest relevant information\n+        - Use a conversational, helpful tone\n+        - Structure your response clearly with bullet points if needed\n         \"\"\"\n         \n         response = self.llm_service.query_llm(followup_prompt)\n@@ -163,14 +177,21 @@ def _handle_followup_query(self, query: str) -> str:\n         self.memory.add_conversation(query, response)\n         \n         return f\"\"\"\n-\ud83d\udcac FOLLOW-UP RESPONSE ({self.memory.current_session['product']})\n+\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n+\u2502 \ud83d\udcac CONVERSATIONAL RESPONSE - {self.memory.current_session['product'].upper():<40} \u2502\n+\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n \n {response}\n \n-\ud83d\udca1 Ask more questions about this product, or type 'exit' to start fresh research.\n+\ud83d\udca1 Continue asking questions about {self.memory.current_session['product']} or type 'exit' for new research.\n         \"\"\".strip()\n     \n     def clear_memory(self):\n         \"\"\"Clear conversation memory\"\"\"\n         self.memory.clear_session()\n     \n+    def __del__(self):\n+        \"\"\"Cleanup when orchestrator is destroyed\"\"\"\n+        if hasattr(self, 'memory'):\n+            self.memory.clear_session()\n+    ",
      "patch_lines": [
        "@@ -112,23 +112,35 @@ def _is_new_research_query(self, query: str) -> bool:\n",
        "         query_lower = query.lower()\n",
        "         \n",
        "         # Keywords that clearly indicate follow-up questions\n",
        "-        followup_keywords = ['camera', 'battery', 'price', 'color', 'colors', 'screen', 'display', \n",
        "-                           'performance', 'storage', 'memory', 'size', 'weight', 'features',\n",
        "-                           'what', 'how', 'when', 'where', 'why', 'is it', 'does it', 'can it',\n",
        "-                           'details', 'detail', 'about', 'specs', 'specification']\n",
        "+        followup_keywords = [\n",
        "+            'camera', 'battery', 'price', 'color', 'colors', 'screen', 'display', \n",
        "+            'performance', 'storage', 'memory', 'size', 'weight', 'features',\n",
        "+            'what', 'how', 'when', 'where', 'why', 'is it', 'does it', 'can it',\n",
        "+            'details', 'detail', 'about', 'specs', 'specification', 'tell me',\n",
        "+            'more about', 'explain', 'describe', 'show me', 'good', 'bad',\n",
        "+            'pros', 'cons', 'worth', 'buy', 'purchase', 'recommend'\n",
        "+        ]\n",
        "+        \n",
        "+        # Short queries are likely follow-ups\n",
        "+        if len(query.split()) <= 3:\n",
        "+            return False\n",
        "         \n",
        "         # If it's clearly a follow-up question\n",
        "         if any(keyword in query_lower for keyword in followup_keywords):\n",
        "             return False\n",
        "         \n",
        "         # Keywords that indicate new research\n",
        "-        new_research_keywords = ['review of', 'analysis of', 'compare with']\n",
        "+        new_research_keywords = ['review of', 'analysis of', 'compare', 'vs', 'versus']\n",
        "         \n",
        "         # If query contains completely different product names\n",
        "         if self.memory.current_session:\n",
        "             current_product = self.memory.current_session['product'].lower()\n",
        "-            different_products = ['iphone', 'samsung', 'oneplus', 'xiaomi', 'huawei', 'sony', 'lg']\n",
        "-            if any(product in query_lower for product in different_products) and not any(word in current_product for word in query_lower.split()):\n",
        "+            # Check if query mentions a completely different product\n",
        "+            product_brands = ['iphone', 'samsung', 'oneplus', 'xiaomi', 'huawei', 'sony', 'lg', 'pixel', 'galaxy']\n",
        "+            mentioned_products = [p for p in product_brands if p in query_lower]\n",
        "+            current_products = [p for p in product_brands if p in current_product]\n",
        "+            \n",
        "+            if mentioned_products and current_products and not any(p in current_products for p in mentioned_products):\n",
        "                 return True\n",
        "         \n",
        "         # If it contains explicit new research keywords\n",
        "@@ -143,18 +155,20 @@ def _handle_followup_query(self, query: str) -> str:\n",
        "         \n",
        "         # Create focused prompt for follow-up\n",
        "         followup_prompt = f\"\"\"\n",
        "-        You are answering a follow-up question about {self.memory.current_session['product']} using previously researched data.\n",
        "+        You are a product expert answering a follow-up question about {self.memory.current_session['product']}.\n",
        "         \n",
        "-        QUESTION: {query}\n",
        "+        USER QUESTION: {query}\n",
        "         \n",
        "-        RESEARCH DATA:\n",
        "+        AVAILABLE RESEARCH DATA:\n",
        "         {research_context}\n",
        "         \n",
        "         INSTRUCTIONS:\n",
        "-        - Answer the specific question using the research data\n",
        "-        - Be concise and direct\n",
        "-        - Reference specific details from the research when relevant\n",
        "-        - If the question can't be answered from the data, say so\n",
        "+        - Answer the specific question using the research data provided\n",
        "+        - Be detailed and informative while staying focused on the question\n",
        "+        - Reference specific details from reviews, specs, or user feedback when relevant\n",
        "+        - If the exact information isn't in the data, provide the closest relevant information\n",
        "+        - Use a conversational, helpful tone\n",
        "+        - Structure your response clearly with bullet points if needed\n",
        "         \"\"\"\n",
        "         \n",
        "         response = self.llm_service.query_llm(followup_prompt)\n",
        "@@ -163,14 +177,21 @@ def _handle_followup_query(self, query: str) -> str:\n",
        "         self.memory.add_conversation(query, response)\n",
        "         \n",
        "         return f\"\"\"\n",
        "-\ud83d\udcac FOLLOW-UP RESPONSE ({self.memory.current_session['product']})\n",
        "+\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "+\u2502 \ud83d\udcac CONVERSATIONAL RESPONSE - {self.memory.current_session['product'].upper():<40} \u2502\n",
        "+\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        " \n",
        " {response}\n",
        " \n",
        "-\ud83d\udca1 Ask more questions about this product, or type 'exit' to start fresh research.\n",
        "+\ud83d\udca1 Continue asking questions about {self.memory.current_session['product']} or type 'exit' for new research.\n",
        "         \"\"\".strip()\n",
        "     \n",
        "     def clear_memory(self):\n",
        "         \"\"\"Clear conversation memory\"\"\"\n",
        "         self.memory.clear_session()\n",
        "     \n",
        "+    def __del__(self):\n",
        "+        \"\"\"Cleanup when orchestrator is destroyed\"\"\"\n",
        "+        if hasattr(self, 'memory'):\n",
        "+            self.memory.clear_session()\n",
        "+    \n"
      ]
    },
    {
      "path": "main.py",
      "status": "modified",
      "additions": 0,
      "deletions": 1,
      "patch": "@@ -72,7 +72,6 @@ def main():\n             print()\n             # Process the query\n             result = orchestrator.analyze_query(user_input)\n-            print()\n             print(result)\n             print()\n             ",
      "patch_lines": [
        "@@ -72,7 +72,6 @@ def main():\n",
        "             print()\n",
        "             # Process the query\n",
        "             result = orchestrator.analyze_query(user_input)\n",
        "-            print()\n",
        "             print(result)\n",
        "             print()\n",
        "             \n"
      ]
    }
  ]
}