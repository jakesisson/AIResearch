{
  "project": "Research Data/MemGPT-Discord",
  "repo": "Alexanderdunlop/MemGPT-Discord",
  "prior_commit": "77cff2f5636ae3b322d9e3b2cca1a1de5a90a4e9",
  "researched_commit": "9eb09b5b228db748c740c20b656691b156ee3dd4",
  "compare_url": "https://github.com/Alexanderdunlop/MemGPT-Discord/compare/77cff2f5636ae3b322d9e3b2cca1a1de5a90a4e9...9eb09b5b228db748c740c20b656691b156ee3dd4",
  "ahead_by": 1,
  "behind_by": 0,
  "changed_files": [
    {
      "path": "main.py",
      "status": "modified",
      "additions": 51,
      "deletions": 80,
      "patch": "@@ -7,16 +7,20 @@\n import asyncio\n import logging\n import os\n-import uuid\n \n import discord\n from aiohttp import web\n from discord.ext import commands\n from discord.message import Message\n from dotenv import load_dotenv\n-from langchain_core.messages import HumanMessage\n+from langchain_core.messages import HumanMessage, AIMessage\n from langgraph_sdk.schema import Thread\n from my_agent.agent import graph\n+from my_agent.utils.state import AgentState\n+from my_agent.utils.schemas import GraphConfig\n+\n+from datetime import datetime, timezone, timedelta\n+from typing import List\n \n logging.basicConfig(level=logging.INFO)\n logger = logging.getLogger(\"discord\")\n@@ -34,45 +38,12 @@\n INTENTS = discord.Intents.default()\n INTENTS.message_content = True\n BOT = commands.Bot(command_prefix=\"!\", intents=INTENTS)\n-# _LANGGRAPH_CLIENT = get_client(url=os.environ[\"ASSISTANT_URL\"])\n-_ASSISTANT_ID = os.environ.get(\"ASSISTANT_ID\")\n-_GRAPH_ID = os.environ.get(\"GRAPH_ID\", \"memory\")\n-_LOCK = asyncio.Lock()\n-\n \n @BOT.event\n async def on_ready():\n     \"\"\"Log a message when the bot has successfully connected to Discord.\"\"\"\n     logger.info(f\"{BOT.user} has connected to Discord!\")\n \n-\n-async def _get_assistant_id() -> str:\n-    \"\"\"Retrieve or set the assistant ID for the bot.\n-\n-    This function checks if an assistant ID is already set. If not, it fetches\n-    the first available assistant from the LangGraph client and sets it as the\n-    current assistant ID.\n-\n-    Returns:\n-        str: The assistant ID to be used for processing messages.\n-\n-    Raises:\n-        ValueError: If no assistant is found in the graph.\n-    \"\"\"\n-    global _ASSISTANT_ID\n-    if _ASSISTANT_ID is None:\n-        async with _LOCK:\n-            if _ASSISTANT_ID is None:\n-                assistants = await graph.assistants.search(\n-                    graph_id=_GRAPH_ID\n-                )\n-                if not assistants:\n-                    raise ValueError(\"No assistant found in the graph.\")\n-                _ASSISTANT_ID = assistants[0][\"assistant_id\"]\n-                logger.warning(f\"Using assistant ID: {_ASSISTANT_ID}\")\n-    return _ASSISTANT_ID\n-\n-\n async def _get_thread(message: Message) -> discord.Thread:\n     \"\"\"Get or create a Discord thread for the given message.\n \n@@ -91,44 +62,36 @@ async def _get_thread(message: Message) -> discord.Thread:\n     else:\n         return await channel.create_thread(name=\"Response\", message=message)\n \n-\n-async def _create_or_fetch_lg_thread(thread_id: uuid.UUID) -> Thread:\n-    \"\"\"Create or fetch a LangGraph thread for the given thread ID.\n-\n-    This function attempts to fetch an existing LangGraph thread. If it doesn't\n-    exist, a new thread is created.\n-\n-    Args:\n-        thread_id (uuid.UUID): The unique identifier for the thread.\n-\n-    Returns:\n-        Thread: The LangGraph thread object.\n-    \"\"\"\n-    try:\n-        return await graph.threads.get(thread_id)\n-    except Exception:\n-        pass\n-    return await graph.threads.create(thread_id=thread_id)\n+async def _get_thread_messages(thread: discord.Thread, current_message: Message) -> List[Message]:\n+    start = datetime.now(tz=timezone.utc) - timedelta(days=1)\n+    end = datetime.now(tz=timezone.utc)\n+    \n+    formatted_messages = []\n+    async for message in thread.history(after=start, before=end):\n+        if message.type == discord.MessageType.thread_starter_message:\n+            continue\n+        if message.author == BOT.user:\n+            formatted_messages.append(AIMessage(content=message.content))\n+        else:\n+            formatted_messages.append(HumanMessage(content=message.content))\n+    return formatted_messages\n \n \n def _format_inbound_message(message: Message) -> HumanMessage:\n-    \"\"\"Format a Discord message into a HumanMessage for LangGraph processing.\n-\n-    This function takes a Discord message and formats it into a structured\n-    HumanMessage object that includes context about the message's origin.\n-\n-    Args:\n-        message (Message): The Discord message to format.\n-\n-    Returns:\n-        HumanMessage: A formatted message ready for LangGraph processing.\n-    \"\"\"\n+    \"\"\"Format a Discord message into a HumanMessage for LangGraph processing.\"\"\"\n     guild_str = \"\" if message.guild is None else f\"guild={message.guild}\"\n     content = f\"\"\"<discord {guild_str} channel={message.channel} author={repr(message.author)}>\n     {message.content}\n     </discord>\"\"\"\n+    \n+    # Sanitize the name to only include valid characters\n+    safe_name = str(message.author.global_name or message.author.name)\n+    safe_name = \"\".join(c for c in safe_name if c.isalnum() or c in \"_-\")\n+    \n     return HumanMessage(\n-        content=content, name=str(message.author.global_name), id=str(message.id)\n+        content=content,\n+        name=safe_name,  # Use sanitized name\n+        id=str(message.id)\n     )\n \n \n@@ -146,25 +109,33 @@ async def on_message(message: Message):\n     if message.author == BOT.user:\n         return\n     if BOT.user.mentioned_in(message):\n-        aid = await _get_assistant_id()\n         thread = await _get_thread(message)\n-        lg_thread = await _create_or_fetch_lg_thread(\n-            uuid.uuid5(uuid.NAMESPACE_DNS, f\"DISCORD:{thread.id}\")\n+        messages = await _get_thread_messages(thread, current_message=message)\n+\n+        new_message = _format_inbound_message(message)\n+        messages.append(new_message)\n+\n+        # Create initial state with empty memories\n+        initial_state = AgentState(\n+            messages=messages,\n+            core_memories=[], \n+            recall_memories=[], \n         )\n-        thread_id = lg_thread[\"thread_id\"]\n-        user_id = message.author.id  # TODO: is this unique?\n-        run_result = await graph.runs.wait(\n-            thread_id,\n-            assistant_id=aid,\n-            input={\"messages\": [_format_inbound_message(message)]},\n-            config={\n-                \"configurable\": {\n-                    \"user_id\": user_id,\n-                }\n-            },\n+\n+        # Create config with thread and user context\n+        config = GraphConfig(\n+            input=new_message.content,  # Changed to use new_message.content directly\n+            chat_history=[msg.content for msg in messages],  # Add full chat history\n+            context=[],\n+            thread_id=str(thread.id),  # Ensure thread_id is string\n+            user_id=str(message.author.id),  # Ensure user_id is string\n         )\n+\n+        run_result = await graph.ainvoke(initial_state, config)\n+        \n+        # Extract and send response\n         bot_message = run_result[\"messages\"][-1]\n-        response = bot_message[\"content\"]\n+        response = bot_message.content\n         if isinstance(response, list):\n             response = \"\".join([r[\"text\"] for r in response])\n         await thread.send(response)",
      "patch_lines": [
        "@@ -7,16 +7,20 @@\n",
        " import asyncio\n",
        " import logging\n",
        " import os\n",
        "-import uuid\n",
        " \n",
        " import discord\n",
        " from aiohttp import web\n",
        " from discord.ext import commands\n",
        " from discord.message import Message\n",
        " from dotenv import load_dotenv\n",
        "-from langchain_core.messages import HumanMessage\n",
        "+from langchain_core.messages import HumanMessage, AIMessage\n",
        " from langgraph_sdk.schema import Thread\n",
        " from my_agent.agent import graph\n",
        "+from my_agent.utils.state import AgentState\n",
        "+from my_agent.utils.schemas import GraphConfig\n",
        "+\n",
        "+from datetime import datetime, timezone, timedelta\n",
        "+from typing import List\n",
        " \n",
        " logging.basicConfig(level=logging.INFO)\n",
        " logger = logging.getLogger(\"discord\")\n",
        "@@ -34,45 +38,12 @@\n",
        " INTENTS = discord.Intents.default()\n",
        " INTENTS.message_content = True\n",
        " BOT = commands.Bot(command_prefix=\"!\", intents=INTENTS)\n",
        "-# _LANGGRAPH_CLIENT = get_client(url=os.environ[\"ASSISTANT_URL\"])\n",
        "-_ASSISTANT_ID = os.environ.get(\"ASSISTANT_ID\")\n",
        "-_GRAPH_ID = os.environ.get(\"GRAPH_ID\", \"memory\")\n",
        "-_LOCK = asyncio.Lock()\n",
        "-\n",
        " \n",
        " @BOT.event\n",
        " async def on_ready():\n",
        "     \"\"\"Log a message when the bot has successfully connected to Discord.\"\"\"\n",
        "     logger.info(f\"{BOT.user} has connected to Discord!\")\n",
        " \n",
        "-\n",
        "-async def _get_assistant_id() -> str:\n",
        "-    \"\"\"Retrieve or set the assistant ID for the bot.\n",
        "-\n",
        "-    This function checks if an assistant ID is already set. If not, it fetches\n",
        "-    the first available assistant from the LangGraph client and sets it as the\n",
        "-    current assistant ID.\n",
        "-\n",
        "-    Returns:\n",
        "-        str: The assistant ID to be used for processing messages.\n",
        "-\n",
        "-    Raises:\n",
        "-        ValueError: If no assistant is found in the graph.\n",
        "-    \"\"\"\n",
        "-    global _ASSISTANT_ID\n",
        "-    if _ASSISTANT_ID is None:\n",
        "-        async with _LOCK:\n",
        "-            if _ASSISTANT_ID is None:\n",
        "-                assistants = await graph.assistants.search(\n",
        "-                    graph_id=_GRAPH_ID\n",
        "-                )\n",
        "-                if not assistants:\n",
        "-                    raise ValueError(\"No assistant found in the graph.\")\n",
        "-                _ASSISTANT_ID = assistants[0][\"assistant_id\"]\n",
        "-                logger.warning(f\"Using assistant ID: {_ASSISTANT_ID}\")\n",
        "-    return _ASSISTANT_ID\n",
        "-\n",
        "-\n",
        " async def _get_thread(message: Message) -> discord.Thread:\n",
        "     \"\"\"Get or create a Discord thread for the given message.\n",
        " \n",
        "@@ -91,44 +62,36 @@ async def _get_thread(message: Message) -> discord.Thread:\n",
        "     else:\n",
        "         return await channel.create_thread(name=\"Response\", message=message)\n",
        " \n",
        "-\n",
        "-async def _create_or_fetch_lg_thread(thread_id: uuid.UUID) -> Thread:\n",
        "-    \"\"\"Create or fetch a LangGraph thread for the given thread ID.\n",
        "-\n",
        "-    This function attempts to fetch an existing LangGraph thread. If it doesn't\n",
        "-    exist, a new thread is created.\n",
        "-\n",
        "-    Args:\n",
        "-        thread_id (uuid.UUID): The unique identifier for the thread.\n",
        "-\n",
        "-    Returns:\n",
        "-        Thread: The LangGraph thread object.\n",
        "-    \"\"\"\n",
        "-    try:\n",
        "-        return await graph.threads.get(thread_id)\n",
        "-    except Exception:\n",
        "-        pass\n",
        "-    return await graph.threads.create(thread_id=thread_id)\n",
        "+async def _get_thread_messages(thread: discord.Thread, current_message: Message) -> List[Message]:\n",
        "+    start = datetime.now(tz=timezone.utc) - timedelta(days=1)\n",
        "+    end = datetime.now(tz=timezone.utc)\n",
        "+    \n",
        "+    formatted_messages = []\n",
        "+    async for message in thread.history(after=start, before=end):\n",
        "+        if message.type == discord.MessageType.thread_starter_message:\n",
        "+            continue\n",
        "+        if message.author == BOT.user:\n",
        "+            formatted_messages.append(AIMessage(content=message.content))\n",
        "+        else:\n",
        "+            formatted_messages.append(HumanMessage(content=message.content))\n",
        "+    return formatted_messages\n",
        " \n",
        " \n",
        " def _format_inbound_message(message: Message) -> HumanMessage:\n",
        "-    \"\"\"Format a Discord message into a HumanMessage for LangGraph processing.\n",
        "-\n",
        "-    This function takes a Discord message and formats it into a structured\n",
        "-    HumanMessage object that includes context about the message's origin.\n",
        "-\n",
        "-    Args:\n",
        "-        message (Message): The Discord message to format.\n",
        "-\n",
        "-    Returns:\n",
        "-        HumanMessage: A formatted message ready for LangGraph processing.\n",
        "-    \"\"\"\n",
        "+    \"\"\"Format a Discord message into a HumanMessage for LangGraph processing.\"\"\"\n",
        "     guild_str = \"\" if message.guild is None else f\"guild={message.guild}\"\n",
        "     content = f\"\"\"<discord {guild_str} channel={message.channel} author={repr(message.author)}>\n",
        "     {message.content}\n",
        "     </discord>\"\"\"\n",
        "+    \n",
        "+    # Sanitize the name to only include valid characters\n",
        "+    safe_name = str(message.author.global_name or message.author.name)\n",
        "+    safe_name = \"\".join(c for c in safe_name if c.isalnum() or c in \"_-\")\n",
        "+    \n",
        "     return HumanMessage(\n",
        "-        content=content, name=str(message.author.global_name), id=str(message.id)\n",
        "+        content=content,\n",
        "+        name=safe_name,  # Use sanitized name\n",
        "+        id=str(message.id)\n",
        "     )\n",
        " \n",
        " \n",
        "@@ -146,25 +109,33 @@ async def on_message(message: Message):\n",
        "     if message.author == BOT.user:\n",
        "         return\n",
        "     if BOT.user.mentioned_in(message):\n",
        "-        aid = await _get_assistant_id()\n",
        "         thread = await _get_thread(message)\n",
        "-        lg_thread = await _create_or_fetch_lg_thread(\n",
        "-            uuid.uuid5(uuid.NAMESPACE_DNS, f\"DISCORD:{thread.id}\")\n",
        "+        messages = await _get_thread_messages(thread, current_message=message)\n",
        "+\n",
        "+        new_message = _format_inbound_message(message)\n",
        "+        messages.append(new_message)\n",
        "+\n",
        "+        # Create initial state with empty memories\n",
        "+        initial_state = AgentState(\n",
        "+            messages=messages,\n",
        "+            core_memories=[], \n",
        "+            recall_memories=[], \n",
        "         )\n",
        "-        thread_id = lg_thread[\"thread_id\"]\n",
        "-        user_id = message.author.id  # TODO: is this unique?\n",
        "-        run_result = await graph.runs.wait(\n",
        "-            thread_id,\n",
        "-            assistant_id=aid,\n",
        "-            input={\"messages\": [_format_inbound_message(message)]},\n",
        "-            config={\n",
        "-                \"configurable\": {\n",
        "-                    \"user_id\": user_id,\n",
        "-                }\n",
        "-            },\n",
        "+\n",
        "+        # Create config with thread and user context\n",
        "+        config = GraphConfig(\n",
        "+            input=new_message.content,  # Changed to use new_message.content directly\n",
        "+            chat_history=[msg.content for msg in messages],  # Add full chat history\n",
        "+            context=[],\n",
        "+            thread_id=str(thread.id),  # Ensure thread_id is string\n",
        "+            user_id=str(message.author.id),  # Ensure user_id is string\n",
        "         )\n",
        "+\n",
        "+        run_result = await graph.ainvoke(initial_state, config)\n",
        "+        \n",
        "+        # Extract and send response\n",
        "         bot_message = run_result[\"messages\"][-1]\n",
        "-        response = bot_message[\"content\"]\n",
        "+        response = bot_message.content\n",
        "         if isinstance(response, list):\n",
        "             response = \"\".join([r[\"text\"] for r in response])\n",
        "         await thread.send(response)\n"
      ]
    },
    {
      "path": "my_agent/agent.py",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "patch": "@@ -1,13 +1,13 @@\n from langgraph.graph import StateGraph, END\n \n-from my_agent.utils.nodes import call_model, should_continue, tool_node, load_memories\n+from my_agent.utils.nodes import acall_model, should_continue, tool_node, load_memories\n from my_agent.utils.state import AgentState\n from my_agent.utils.schemas import GraphConfig\n \n workflow = StateGraph(AgentState, config_schema=GraphConfig)\n \n workflow.add_node(\"load_memories\", load_memories)\n-workflow.add_node(\"agent\", call_model)\n+workflow.add_node(\"agent\", acall_model)\n workflow.add_node(\"tools\", tool_node)\n \n workflow.set_entry_point(\"load_memories\")",
      "patch_lines": [
        "@@ -1,13 +1,13 @@\n",
        " from langgraph.graph import StateGraph, END\n",
        " \n",
        "-from my_agent.utils.nodes import call_model, should_continue, tool_node, load_memories\n",
        "+from my_agent.utils.nodes import acall_model, should_continue, tool_node, load_memories\n",
        " from my_agent.utils.state import AgentState\n",
        " from my_agent.utils.schemas import GraphConfig\n",
        " \n",
        " workflow = StateGraph(AgentState, config_schema=GraphConfig)\n",
        " \n",
        " workflow.add_node(\"load_memories\", load_memories)\n",
        "-workflow.add_node(\"agent\", call_model)\n",
        "+workflow.add_node(\"agent\", acall_model)\n",
        " workflow.add_node(\"tools\", tool_node)\n",
        " \n",
        " workflow.set_entry_point(\"load_memories\")\n"
      ]
    },
    {
      "path": "my_agent/utils/nodes.py",
      "status": "modified",
      "additions": 8,
      "deletions": 5,
      "patch": "@@ -14,6 +14,7 @@\n import tiktoken\n from dotenv import load_dotenv\n import os\n+from langchain_core.messages import AIMessage\n \n load_dotenv()\n \n@@ -42,10 +43,12 @@ def should_continue(state):\n     \"\"\"\n     messages = state[\"messages\"]\n     last_message = messages[-1]\n-    if not last_message.tool_calls:\n-        return \"end\"\n-    else:\n+    if not isinstance(last_message, AIMessage):\n+        raise TypeError(f\"Expected AIMessage, got {type(last_message)}\")\n+    if last_message.tool_calls:\n         return \"continue\"\n+    else:\n+        return \"end\"\n \n \n system_prompt = (\n@@ -96,7 +99,7 @@ def should_continue(state):\n     \"Current system time: {current_time}\\n\\n\",\n )\n \n-def call_model(state: AgentState):\n+async def acall_model(state: AgentState):\n     \"\"\"Process the current state and generate a response using the LLM.\"\"\"\n \n     messages = state[\"messages\"]\n@@ -121,7 +124,7 @@ def call_model(state: AgentState):\n \n     messages = [{\"role\": \"system\", \"content\": formatted_system_prompt}] + messages\n     model = _get_model()\n-    response = model.invoke(messages)\n+    response = await model.ainvoke(messages)\n     return {\"messages\": [response]}\n \n def load_memories(state: AgentState, config: RunnableConfig) -> AgentState:",
      "patch_lines": [
        "@@ -14,6 +14,7 @@\n",
        " import tiktoken\n",
        " from dotenv import load_dotenv\n",
        " import os\n",
        "+from langchain_core.messages import AIMessage\n",
        " \n",
        " load_dotenv()\n",
        " \n",
        "@@ -42,10 +43,12 @@ def should_continue(state):\n",
        "     \"\"\"\n",
        "     messages = state[\"messages\"]\n",
        "     last_message = messages[-1]\n",
        "-    if not last_message.tool_calls:\n",
        "-        return \"end\"\n",
        "-    else:\n",
        "+    if not isinstance(last_message, AIMessage):\n",
        "+        raise TypeError(f\"Expected AIMessage, got {type(last_message)}\")\n",
        "+    if last_message.tool_calls:\n",
        "         return \"continue\"\n",
        "+    else:\n",
        "+        return \"end\"\n",
        " \n",
        " \n",
        " system_prompt = (\n",
        "@@ -96,7 +99,7 @@ def should_continue(state):\n",
        "     \"Current system time: {current_time}\\n\\n\",\n",
        " )\n",
        " \n",
        "-def call_model(state: AgentState):\n",
        "+async def acall_model(state: AgentState):\n",
        "     \"\"\"Process the current state and generate a response using the LLM.\"\"\"\n",
        " \n",
        "     messages = state[\"messages\"]\n",
        "@@ -121,7 +124,7 @@ def call_model(state: AgentState):\n",
        " \n",
        "     messages = [{\"role\": \"system\", \"content\": formatted_system_prompt}] + messages\n",
        "     model = _get_model()\n",
        "-    response = model.invoke(messages)\n",
        "+    response = await model.ainvoke(messages)\n",
        "     return {\"messages\": [response]}\n",
        " \n",
        " def load_memories(state: AgentState, config: RunnableConfig) -> AgentState:\n"
      ]
    },
    {
      "path": "my_agent/utils/schemas.py",
      "status": "modified",
      "additions": 0,
      "deletions": 3,
      "patch": "@@ -5,9 +5,6 @@\n from typing_extensions import TypedDict\n \n class GraphConfig(TypedDict):\n-    input: str\n-    chat_history: List[str]\n-    context: List[str]\n     thread_id: str\n     user_id: str\n     delay: Optional[int]",
      "patch_lines": [
        "@@ -5,9 +5,6 @@\n",
        " from typing_extensions import TypedDict\n",
        " \n",
        " class GraphConfig(TypedDict):\n",
        "-    input: str\n",
        "-    chat_history: List[str]\n",
        "-    context: List[str]\n",
        "     thread_id: str\n",
        "     user_id: str\n",
        "     delay: Optional[int]\n"
      ]
    },
    {
      "path": "my_agent/utils/state.py",
      "status": "modified",
      "additions": 3,
      "deletions": 0,
      "patch": "@@ -3,6 +3,7 @@\n from langgraph.graph import add_messages\n from langchain_core.messages import AnyMessage\n from typing import TypedDict, Annotated\n+from langgraph.managed import RemainingSteps\n \n class AgentState(TypedDict):\n     messages: Annotated[List[AnyMessage], add_messages]\n@@ -11,3 +12,5 @@ class AgentState(TypedDict):\n     \"\"\"The core memories associated with the user.\"\"\"\n     recall_memories: List[str]\n     \"\"\"The recall memories retrieved for the current context.\"\"\"\n+    remaining_steps: RemainingSteps\n+    \"\"\"Remaining steps in the agent workflow.\"\"\"",
      "patch_lines": [
        "@@ -3,6 +3,7 @@\n",
        " from langgraph.graph import add_messages\n",
        " from langchain_core.messages import AnyMessage\n",
        " from typing import TypedDict, Annotated\n",
        "+from langgraph.managed import RemainingSteps\n",
        " \n",
        " class AgentState(TypedDict):\n",
        "     messages: Annotated[List[AnyMessage], add_messages]\n",
        "@@ -11,3 +12,5 @@ class AgentState(TypedDict):\n",
        "     \"\"\"The core memories associated with the user.\"\"\"\n",
        "     recall_memories: List[str]\n",
        "     \"\"\"The recall memories retrieved for the current context.\"\"\"\n",
        "+    remaining_steps: RemainingSteps\n",
        "+    \"\"\"Remaining steps in the agent workflow.\"\"\"\n"
      ]
    }
  ]
}