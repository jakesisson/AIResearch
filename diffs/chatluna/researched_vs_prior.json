{
  "project": "Research Data/chatluna",
  "repo": "ChatLunaLab/chatluna",
  "prior_commit": "e850d438efacba2ef391155e864fb8e7c7dbbc42",
  "researched_commit": "9f7332529850cceb0b1ab8138540796c6a47890e",
  "compare_url": "https://github.com/ChatLunaLab/chatluna/compare/e850d438efacba2ef391155e864fb8e7c7dbbc42...9f7332529850cceb0b1ab8138540796c6a47890e",
  "ahead_by": 1,
  "behind_by": 0,
  "changed_files": [
    {
      "path": "packages/adapter-azure-openai/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-azure-openai-adapter\",\n     \"description\": \"azure openai adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.14\",\n+    \"version\": \"1.3.0-alpha.15\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -46,7 +46,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -57,7 +57,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"resolutions\": {\n         \"@langchain/core\": \"0.3.62\",",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-azure-openai-adapter\",\n",
        "     \"description\": \"azure openai adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.14\",\n",
        "+    \"version\": \"1.3.0-alpha.15\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -46,7 +46,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -57,7 +57,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"resolutions\": {\n",
        "         \"@langchain/core\": \"0.3.62\",\n"
      ]
    },
    {
      "path": "packages/adapter-claude/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-claude-adapter\",\n     \"description\": \"claude adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.14\",\n+    \"version\": \"1.3.0-alpha.15\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -47,7 +47,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -59,7 +59,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"resolutions\": {\n         \"@langchain/core\": \"0.3.62\",",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-claude-adapter\",\n",
        "     \"description\": \"claude adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.14\",\n",
        "+    \"version\": \"1.3.0-alpha.15\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -47,7 +47,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -59,7 +59,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"resolutions\": {\n",
        "         \"@langchain/core\": \"0.3.62\",\n"
      ]
    },
    {
      "path": "packages/adapter-deepseek/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-deepseek-adapter\",\n     \"description\": \"deepseek adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.14\",\n+    \"version\": \"1.3.0-alpha.15\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -60,7 +60,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -71,7 +71,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"category\": \"ai\",",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-deepseek-adapter\",\n",
        "     \"description\": \"deepseek adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.14\",\n",
        "+    \"version\": \"1.3.0-alpha.15\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -60,7 +60,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -71,7 +71,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"category\": \"ai\",\n"
      ]
    },
    {
      "path": "packages/adapter-dify/package.json",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-dify-adapter\",\n     \"description\": \"dify adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.13\",\n+    \"version\": \"1.3.0-alpha.14\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -70,7 +70,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-dify-adapter\",\n",
        "     \"description\": \"dify adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.13\",\n",
        "+    \"version\": \"1.3.0-alpha.14\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -70,7 +70,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-doubao/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-doubao-adapter\",\n     \"description\": \"doubao adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.14\",\n+    \"version\": \"1.3.0-alpha.15\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -60,7 +60,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -71,7 +71,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-doubao-adapter\",\n",
        "     \"description\": \"doubao adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.14\",\n",
        "+    \"version\": \"1.3.0-alpha.15\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -60,7 +60,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -71,7 +71,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-gemini/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-google-gemini-adapter\",\n     \"description\": \"google-gemini adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.22\",\n+    \"version\": \"1.3.0-alpha.23\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -63,7 +63,7 @@\n     ],\n     \"dependencies\": {\n         \"@anatine/zod-openapi\": \"^2.2.8\",\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"openapi3-ts\": \"^4.5.0\",\n         \"zod\": \"3.25.76\",\n@@ -75,7 +75,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\",\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\",\n         \"koishi-plugin-chatluna-storage-service\": \"^0.0.11\"\n     },\n     \"peerDependenciesMeta\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-google-gemini-adapter\",\n",
        "     \"description\": \"google-gemini adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.22\",\n",
        "+    \"version\": \"1.3.0-alpha.23\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -63,7 +63,7 @@\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "         \"@anatine/zod-openapi\": \"^2.2.8\",\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"openapi3-ts\": \"^4.5.0\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "@@ -75,7 +75,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\",\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\",\n",
        "         \"koishi-plugin-chatluna-storage-service\": \"^0.0.11\"\n",
        "     },\n",
        "     \"peerDependenciesMeta\": {\n"
      ]
    },
    {
      "path": "packages/adapter-gemini/src/requester.ts",
      "status": "modified",
      "additions": 7,
      "deletions": 5,
      "patch": "@@ -497,11 +497,13 @@ export class GeminiRequester\n                 ))\n             ) {\n                 const generationChunk = new ChatGenerationChunk({\n-                    message: new AIMessageChunk(''),\n-                    text: '',\n-                    generationInfo: {\n-                        tokenUsage: parsedChunk.usage\n-                    }\n+                    message: new AIMessageChunk({\n+                        content: '',\n+                        response_metadata: {\n+                            tokenUsage: parsedChunk.usage\n+                        }\n+                    }),\n+                    text: ''\n                 })\n \n                 yield { type: 'generation', generation: generationChunk }",
      "patch_lines": [
        "@@ -497,11 +497,13 @@ export class GeminiRequester\n",
        "                 ))\n",
        "             ) {\n",
        "                 const generationChunk = new ChatGenerationChunk({\n",
        "-                    message: new AIMessageChunk(''),\n",
        "-                    text: '',\n",
        "-                    generationInfo: {\n",
        "-                        tokenUsage: parsedChunk.usage\n",
        "-                    }\n",
        "+                    message: new AIMessageChunk({\n",
        "+                        content: '',\n",
        "+                        response_metadata: {\n",
        "+                            tokenUsage: parsedChunk.usage\n",
        "+                        }\n",
        "+                    }),\n",
        "+                    text: ''\n",
        "                 })\n",
        " \n",
        "                 yield { type: 'generation', generation: generationChunk }\n"
      ]
    },
    {
      "path": "packages/adapter-hunyuan/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-hunyuan-adapter\",\n     \"description\": \"hunyuan adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.12\",\n+    \"version\": \"1.3.0-alpha.13\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -60,7 +60,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -71,7 +71,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-hunyuan-adapter\",\n",
        "     \"description\": \"hunyuan adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.12\",\n",
        "+    \"version\": \"1.3.0-alpha.13\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -60,7 +60,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -71,7 +71,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-ollama/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-ollama-adapter\",\n     \"description\": \"ollama adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.12\",\n+    \"version\": \"1.3.0-alpha.13\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -45,7 +45,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\"\n     },\n     \"devDependencies\": {\n@@ -54,7 +54,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"resolutions\": {\n         \"@langchain/core\": \"0.3.62\",",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-ollama-adapter\",\n",
        "     \"description\": \"ollama adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.12\",\n",
        "+    \"version\": \"1.3.0-alpha.13\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -45,7 +45,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\"\n",
        "     },\n",
        "     \"devDependencies\": {\n",
        "@@ -54,7 +54,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"resolutions\": {\n",
        "         \"@langchain/core\": \"0.3.62\",\n"
      ]
    },
    {
      "path": "packages/adapter-openai-like/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-openai-like-adapter\",\n     \"description\": \"openai style api adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.15\",\n+    \"version\": \"1.3.0-alpha.16\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -60,7 +60,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -71,7 +71,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-openai-like-adapter\",\n",
        "     \"description\": \"openai style api adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.15\",\n",
        "+    \"version\": \"1.3.0-alpha.16\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -60,7 +60,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -71,7 +71,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-openai/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-openai-adapter\",\n     \"description\": \"openai adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.14\",\n+    \"version\": \"1.3.0-alpha.15\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -60,7 +60,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -71,7 +71,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-openai-adapter\",\n",
        "     \"description\": \"openai adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.14\",\n",
        "+    \"version\": \"1.3.0-alpha.15\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -60,7 +60,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -71,7 +71,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-qwen/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-qwen-adapter\",\n     \"description\": \"qwen adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.15\",\n+    \"version\": \"1.3.0-alpha.16\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -60,7 +60,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -71,7 +71,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-qwen-adapter\",\n",
        "     \"description\": \"qwen adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.15\",\n",
        "+    \"version\": \"1.3.0-alpha.16\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -60,7 +60,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -71,7 +71,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-qwen/src/requester.ts",
      "status": "modified",
      "additions": 11,
      "deletions": 8,
      "patch": "@@ -141,15 +141,18 @@ export class QWenRequester\n \n                 if (data.usage) {\n                     yield new ChatGenerationChunk({\n-                        message: new AIMessageChunk(''),\n-                        text: '',\n-                        generationInfo: {\n-                            tokenUsage: {\n-                                promptTokens: data.usage.prompt_tokens,\n-                                completionTokens: data.usage.completion_tokens,\n-                                totalTokens: data.usage.total_tokens\n+                        message: new AIMessageChunk({\n+                            content: '',\n+                            response_metadata: {\n+                                tokenUsage: {\n+                                    promptTokens: data.usage.prompt_tokens,\n+                                    completionTokens:\n+                                        data.usage.completion_tokens,\n+                                    totalTokens: data.usage.total_tokens\n+                                }\n                             }\n-                        }\n+                        }),\n+                        text: ''\n                     })\n                 }\n ",
      "patch_lines": [
        "@@ -141,15 +141,18 @@ export class QWenRequester\n",
        " \n",
        "                 if (data.usage) {\n",
        "                     yield new ChatGenerationChunk({\n",
        "-                        message: new AIMessageChunk(''),\n",
        "-                        text: '',\n",
        "-                        generationInfo: {\n",
        "-                            tokenUsage: {\n",
        "-                                promptTokens: data.usage.prompt_tokens,\n",
        "-                                completionTokens: data.usage.completion_tokens,\n",
        "-                                totalTokens: data.usage.total_tokens\n",
        "+                        message: new AIMessageChunk({\n",
        "+                            content: '',\n",
        "+                            response_metadata: {\n",
        "+                                tokenUsage: {\n",
        "+                                    promptTokens: data.usage.prompt_tokens,\n",
        "+                                    completionTokens:\n",
        "+                                        data.usage.completion_tokens,\n",
        "+                                    totalTokens: data.usage.total_tokens\n",
        "+                                }\n",
        "                             }\n",
        "-                        }\n",
        "+                        }),\n",
        "+                        text: ''\n",
        "                     })\n",
        "                 }\n",
        " \n"
      ]
    },
    {
      "path": "packages/adapter-rwkv/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-rmkv-adapter\",\n     \"description\": \"rwkv adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.12\",\n+    \"version\": \"1.3.0-alpha.13\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -45,7 +45,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod-to-json-schema\": \"3.23.5\"\n     },\n@@ -69,7 +69,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-rmkv-adapter\",\n",
        "     \"description\": \"rwkv adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.12\",\n",
        "+    \"version\": \"1.3.0-alpha.13\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -45,7 +45,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod-to-json-schema\": \"3.23.5\"\n",
        "     },\n",
        "@@ -69,7 +69,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-spark/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-spark-adapter\",\n     \"description\": \"spark adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.12\",\n+    \"version\": \"1.3.0-alpha.13\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -61,7 +61,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -72,7 +72,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-spark-adapter\",\n",
        "     \"description\": \"spark adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.12\",\n",
        "+    \"version\": \"1.3.0-alpha.13\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -61,7 +61,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -72,7 +72,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-wenxin/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-wenxin-adapter\",\n     \"description\": \"wenxin adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.12\",\n+    \"version\": \"1.3.0-alpha.13\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -60,7 +60,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"zod\": \"3.25.76\",\n         \"zod-to-json-schema\": \"^3.24.6\"\n@@ -71,7 +71,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-wenxin-adapter\",\n",
        "     \"description\": \"wenxin adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.12\",\n",
        "+    \"version\": \"1.3.0-alpha.13\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -60,7 +60,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "         \"zod-to-json-schema\": \"^3.24.6\"\n",
        "@@ -71,7 +71,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-zhipu/package.json",
      "status": "modified",
      "additions": 3,
      "deletions": 3,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna-zhipu-adapter\",\n     \"description\": \"zhipu(chatglm) adapter for chatluna\",\n-    \"version\": \"1.3.0-alpha.14\",\n+    \"version\": \"1.3.0-alpha.15\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -60,7 +60,7 @@\n         \"adapter\"\n     ],\n     \"dependencies\": {\n-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n         \"@langchain/core\": \"0.3.62\",\n         \"jsonwebtoken\": \"^9.0.2\",\n         \"zod\": \"3.25.76\",\n@@ -73,7 +73,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna-zhipu-adapter\",\n",
        "     \"description\": \"zhipu(chatglm) adapter for chatluna\",\n",
        "-    \"version\": \"1.3.0-alpha.14\",\n",
        "+    \"version\": \"1.3.0-alpha.15\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -60,7 +60,7 @@\n",
        "         \"adapter\"\n",
        "     ],\n",
        "     \"dependencies\": {\n",
        "-        \"@chatluna/v1-shared-adapter\": \"^1.0.15\",\n",
        "+        \"@chatluna/v1-shared-adapter\": \"^1.0.16\",\n",
        "         \"@langchain/core\": \"0.3.62\",\n",
        "         \"jsonwebtoken\": \"^9.0.2\",\n",
        "         \"zod\": \"3.25.76\",\n",
        "@@ -73,7 +73,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/adapter-zhipu/src/requester.ts",
      "status": "modified",
      "additions": 11,
      "deletions": 8,
      "patch": "@@ -136,15 +136,18 @@ export class ZhipuRequester\n \n                 if (data.usage) {\n                     yield new ChatGenerationChunk({\n-                        message: new AIMessageChunk(''),\n-                        text: '',\n-                        generationInfo: {\n-                            tokenUsage: {\n-                                promptTokens: data.usage.prompt_tokens,\n-                                completionTokens: data.usage.completion_tokens,\n-                                totalTokens: data.usage.total_tokens\n+                        message: new AIMessageChunk({\n+                            content: '',\n+                            response_metadata: {\n+                                tokenUsage: {\n+                                    promptTokens: data.usage.prompt_tokens,\n+                                    completionTokens:\n+                                        data.usage.completion_tokens,\n+                                    totalTokens: data.usage.total_tokens\n+                                }\n                             }\n-                        }\n+                        }),\n+                        text: ''\n                     })\n                 }\n ",
      "patch_lines": [
        "@@ -136,15 +136,18 @@ export class ZhipuRequester\n",
        " \n",
        "                 if (data.usage) {\n",
        "                     yield new ChatGenerationChunk({\n",
        "-                        message: new AIMessageChunk(''),\n",
        "-                        text: '',\n",
        "-                        generationInfo: {\n",
        "-                            tokenUsage: {\n",
        "-                                promptTokens: data.usage.prompt_tokens,\n",
        "-                                completionTokens: data.usage.completion_tokens,\n",
        "-                                totalTokens: data.usage.total_tokens\n",
        "+                        message: new AIMessageChunk({\n",
        "+                            content: '',\n",
        "+                            response_metadata: {\n",
        "+                                tokenUsage: {\n",
        "+                                    promptTokens: data.usage.prompt_tokens,\n",
        "+                                    completionTokens:\n",
        "+                                        data.usage.completion_tokens,\n",
        "+                                    totalTokens: data.usage.total_tokens\n",
        "+                                }\n",
        "                             }\n",
        "-                        }\n",
        "+                        }),\n",
        "+                        text: ''\n",
        "                     })\n",
        "                 }\n",
        " \n"
      ]
    },
    {
      "path": "packages/core/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"koishi-plugin-chatluna\",\n     \"description\": \"chatluna for koishi\",\n-    \"version\": \"1.3.0-alpha.76\",\n+    \"version\": \"1.3.0-alpha.77\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"koishi-plugin-chatluna\",\n",
        "     \"description\": \"chatluna for koishi\",\n",
        "-    \"version\": \"1.3.0-alpha.76\",\n",
        "+    \"version\": \"1.3.0-alpha.77\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n"
      ]
    },
    {
      "path": "packages/core/src/llm-core/platform/model.ts",
      "status": "modified",
      "additions": 161,
      "deletions": 59,
      "patch": "@@ -19,7 +19,10 @@ import {\n     ModelRequester,\n     ModelRequestParams\n } from 'koishi-plugin-chatluna/llm-core/platform/api'\n-import { ModelInfo } from 'koishi-plugin-chatluna/llm-core/platform/types'\n+import {\n+    ModelInfo,\n+    TokenUsageTracker\n+} from 'koishi-plugin-chatluna/llm-core/platform/types'\n import {\n     getModelContextSize,\n     getModelNameForTiktoken,\n@@ -196,84 +199,179 @@ export class ChatLunaChatModel extends BaseChatModel<ChatLunaModelCallOptions> {\n             ;[messages] = await this.cropMessages(messages, options['tools'])\n         }\n \n-        const stream = await this._createStreamWithRetry({\n+        const maxRetries = Math.max(1, this._options.maxRetries ?? 1)\n+        const streamParams = {\n             ...this.invocationParams(options),\n             input: messages\n-        })\n+        }\n+\n+        for (let attempt = 0; attempt < maxRetries; attempt++) {\n+            const latestTokenUsage = this._createTokenUsageTracker()\n+            let stream: AsyncGenerator<ChatGenerationChunk> | null = null\n+            let hasChunk = false\n+            let isToolCallMessage = false\n+\n+            try {\n+                stream = await this._createStreamWithRetry(streamParams)\n+\n+                for await (const chunk of stream) {\n+                    isToolCallMessage = this._handleStreamChunk(\n+                        chunk,\n+                        runManager,\n+                        latestTokenUsage\n+                    )\n+                    hasChunk = true\n+                    yield chunk\n+                }\n \n-        let isToolCallMessage = false\n-        let hasChunk = false\n+                this._ensureChunksReceived(hasChunk)\n+                this._finalizeStream(\n+                    isToolCallMessage,\n+                    latestTokenUsage,\n+                    runManager\n+                )\n+                return\n+            } catch (error) {\n+                await this._closeStream(stream)\n+\n+                if (\n+                    this._shouldRethrowStreamError(\n+                        error,\n+                        hasChunk,\n+                        attempt,\n+                        maxRetries\n+                    )\n+                ) {\n+                    throw error\n+                }\n \n-        const latestTokenUsage: {\n-            promptTokens: number\n-            completionTokens: number\n-            totalTokens: number\n-        } = {\n+                await sleep(2000)\n+            }\n+        }\n+    }\n+\n+    private _createTokenUsageTracker(): TokenUsageTracker {\n+        return {\n             promptTokens: 0,\n             completionTokens: 0,\n             totalTokens: 0\n         }\n+    }\n \n-        for await (const chunk of stream) {\n-            yield chunk\n+    private _handleStreamChunk(\n+        chunk: ChatGenerationChunk,\n+        runManager: CallbackManagerForLLMRun | undefined,\n+        latestTokenUsage: TokenUsageTracker\n+    ): boolean {\n+        const chunkText = chunk.text ?? ''\n \n-            const chunkText = chunk.text ?? ''\n+        if (chunkText) {\n+            // eslint-disable-next-line no-void\n+            void runManager?.handleLLMNewToken(chunkText)\n+        }\n \n-            if (chunkText != null) {\n-                // eslint-disable-next-line no-void\n-                void runManager?.handleLLMNewToken(chunkText)\n+        const message = chunk.message as AIMessageChunk | undefined\n+        const isToolCallMessage = this._isToolCallMessage(message)\n \n-                isToolCallMessage =\n-                    ((chunk.message as AIMessageChunk)?.tool_calls?.length ??\n-                        0) === 0 &&\n-                    ((chunk.message as AIMessageChunk)?.tool_call_chunks\n-                        ?.length ?? 0) === 0 &&\n-                    ((chunk.message as AIMessageChunk)?.invalid_tool_calls\n-                        ?.length ?? 0) === 0\n+        if (isToolCallMessage) {\n+            // eslint-disable-next-line no-void\n+            void runManager?.handleCustomEvent('LLMNewChunk', message)\n+        }\n \n-                if (isToolCallMessage) {\n-                    // eslint-disable-next-line no-void\n-                    void runManager?.handleCustomEvent(\n-                        'LLMNewChunk',\n-                        chunk.message\n-                    )\n-                }\n-            }\n+        this._updateTokenUsageFromChunk(chunk, latestTokenUsage)\n \n-            if (\n-                chunk.generationInfo != null &&\n-                chunk.generationInfo['tokenUsage'] != null\n-            ) {\n-                latestTokenUsage.promptTokens =\n-                    chunk.generationInfo['tokenUsage']['promptTokens']\n-                latestTokenUsage.completionTokens =\n-                    chunk.generationInfo['tokenUsage']['completionTokens']\n-                latestTokenUsage.totalTokens =\n-                    chunk.generationInfo['tokenUsage']['totalTokens']\n-            }\n+        return isToolCallMessage\n+    }\n+\n+    private _isToolCallMessage(message?: AIMessageChunk): boolean {\n+        return (\n+            (message?.tool_calls?.length ?? 0) === 0 &&\n+            (message?.tool_call_chunks?.length ?? 0) === 0 &&\n+            (message?.invalid_tool_calls?.length ?? 0) === 0\n+        )\n+    }\n \n-            if (!hasChunk) hasChunk = true\n+    private _updateTokenUsageFromChunk(\n+        chunk: ChatGenerationChunk,\n+        latestTokenUsage: TokenUsageTracker\n+    ) {\n+        const tokenUsage = chunk.message.response_metadata?.['tokenUsage']\n+\n+        if (!tokenUsage) {\n+            return\n         }\n \n-        if (!hasChunk) {\n-            throw new ChatLunaError(ChatLunaErrorCode.API_REQUEST_FAILED)\n+        latestTokenUsage.promptTokens = tokenUsage['promptTokens']\n+        latestTokenUsage.completionTokens = tokenUsage['completionTokens']\n+        latestTokenUsage.totalTokens = tokenUsage['totalTokens']\n+    }\n+\n+    private _ensureChunksReceived(hasChunk: boolean) {\n+        if (hasChunk) {\n+            return\n         }\n \n+        throw new ChatLunaError(ChatLunaErrorCode.API_REQUEST_FAILED)\n+    }\n+\n+    private _finalizeStream(\n+        isToolCallMessage: boolean,\n+        latestTokenUsage: TokenUsageTracker,\n+        runManager?: CallbackManagerForLLMRun\n+    ) {\n         if (isToolCallMessage) {\n             // eslint-disable-next-line no-void\n             void runManager?.handleCustomEvent('LLMNewChunk', undefined)\n         }\n \n-        if (latestTokenUsage.totalTokens > 0) {\n+        if (latestTokenUsage.totalTokens <= 0) {\n+            return\n+        }\n+\n+        logger.debug(\n+            'Token usage from API: Prompt Token = %d, Completion Token = %d, Total Token = %d',\n+            latestTokenUsage.promptTokens,\n+            latestTokenUsage.completionTokens,\n+            latestTokenUsage.totalTokens\n+        )\n+    }\n+\n+    private async _closeStream(\n+        stream: AsyncGenerator<ChatGenerationChunk> | null\n+    ) {\n+        if (stream?.return == null) {\n+            return\n+        }\n+\n+        try {\n+            await stream.return(undefined)\n+        } catch (error) {\n             logger.debug(\n-                'Token usage from API: Prompt Token = %d, Completion Token = %d, Total Token = %d',\n-                latestTokenUsage.promptTokens,\n-                latestTokenUsage.completionTokens,\n-                latestTokenUsage.totalTokens\n+                'Failed to close stream on retry: %s',\n+                (error as Error)?.message\n             )\n         }\n     }\n \n+    private _shouldRethrowStreamError(\n+        error: unknown,\n+        hasChunk: boolean,\n+        attempt: number,\n+        maxRetries: number\n+    ): boolean {\n+        return (\n+            this._isAbortError(error) || hasChunk || attempt === maxRetries - 1\n+        )\n+    }\n+\n+    private _isAbortError(error: unknown): boolean {\n+        if (error instanceof ChatLunaError) {\n+            return error.errorCode === ChatLunaErrorCode.ABORTED\n+        }\n+\n+        return (error as Error)?.name === 'AbortError'\n+    }\n+\n     async _generate(\n         messages: BaseMessage[],\n         options: this['ParsedCallOptions'],\n@@ -295,24 +393,28 @@ export class ChatLunaChatModel extends BaseChatModel<ChatLunaModelCallOptions> {\n             throw new ChatLunaError(ChatLunaErrorCode.API_REQUEST_FAILED)\n         }\n \n-        response.generationInfo = response.generationInfo ?? {}\n+        response.message.response_metadata =\n+            response.message.response_metadata ?? {}\n \n-        if (response.generationInfo.tokenUsage == null) {\n+        if (!response.message.response_metadata.tokenUsage) {\n             const completionTokens = await this.countMessageTokens(\n                 response.message\n             )\n-            response.generationInfo.tokenUsage = {\n+            response.message.response_metadata.tokenUsage = {\n                 completionTokens,\n                 promptTokens,\n                 totalTokens: completionTokens + promptTokens\n             }\n         } else if (options.stream !== true) {\n-            logger.debug(\n-                'Token usage from API: Prompt Token = %d, Completion Token = %d, Total Token = %d',\n-                response.generationInfo['tokenUsage']['promptTokens'],\n-                response.generationInfo['tokenUsage']['completionTokens'],\n-                response.generationInfo['tokenUsage']['totalTokens']\n-            )\n+            const tokenUsage = response.message.response_metadata['tokenUsage']\n+            if (tokenUsage) {\n+                logger.debug(\n+                    'Token usage from API: Prompt Token = %d, Completion Token = %d, Total Token = %d',\n+                    tokenUsage.promptTokens,\n+                    tokenUsage.completionTokens,\n+                    tokenUsage.totalTokens\n+                )\n+            }\n         }\n \n         return {",
      "patch_lines": [
        "@@ -19,7 +19,10 @@ import {\n",
        "     ModelRequester,\n",
        "     ModelRequestParams\n",
        " } from 'koishi-plugin-chatluna/llm-core/platform/api'\n",
        "-import { ModelInfo } from 'koishi-plugin-chatluna/llm-core/platform/types'\n",
        "+import {\n",
        "+    ModelInfo,\n",
        "+    TokenUsageTracker\n",
        "+} from 'koishi-plugin-chatluna/llm-core/platform/types'\n",
        " import {\n",
        "     getModelContextSize,\n",
        "     getModelNameForTiktoken,\n",
        "@@ -196,84 +199,179 @@ export class ChatLunaChatModel extends BaseChatModel<ChatLunaModelCallOptions> {\n",
        "             ;[messages] = await this.cropMessages(messages, options['tools'])\n",
        "         }\n",
        " \n",
        "-        const stream = await this._createStreamWithRetry({\n",
        "+        const maxRetries = Math.max(1, this._options.maxRetries ?? 1)\n",
        "+        const streamParams = {\n",
        "             ...this.invocationParams(options),\n",
        "             input: messages\n",
        "-        })\n",
        "+        }\n",
        "+\n",
        "+        for (let attempt = 0; attempt < maxRetries; attempt++) {\n",
        "+            const latestTokenUsage = this._createTokenUsageTracker()\n",
        "+            let stream: AsyncGenerator<ChatGenerationChunk> | null = null\n",
        "+            let hasChunk = false\n",
        "+            let isToolCallMessage = false\n",
        "+\n",
        "+            try {\n",
        "+                stream = await this._createStreamWithRetry(streamParams)\n",
        "+\n",
        "+                for await (const chunk of stream) {\n",
        "+                    isToolCallMessage = this._handleStreamChunk(\n",
        "+                        chunk,\n",
        "+                        runManager,\n",
        "+                        latestTokenUsage\n",
        "+                    )\n",
        "+                    hasChunk = true\n",
        "+                    yield chunk\n",
        "+                }\n",
        " \n",
        "-        let isToolCallMessage = false\n",
        "-        let hasChunk = false\n",
        "+                this._ensureChunksReceived(hasChunk)\n",
        "+                this._finalizeStream(\n",
        "+                    isToolCallMessage,\n",
        "+                    latestTokenUsage,\n",
        "+                    runManager\n",
        "+                )\n",
        "+                return\n",
        "+            } catch (error) {\n",
        "+                await this._closeStream(stream)\n",
        "+\n",
        "+                if (\n",
        "+                    this._shouldRethrowStreamError(\n",
        "+                        error,\n",
        "+                        hasChunk,\n",
        "+                        attempt,\n",
        "+                        maxRetries\n",
        "+                    )\n",
        "+                ) {\n",
        "+                    throw error\n",
        "+                }\n",
        " \n",
        "-        const latestTokenUsage: {\n",
        "-            promptTokens: number\n",
        "-            completionTokens: number\n",
        "-            totalTokens: number\n",
        "-        } = {\n",
        "+                await sleep(2000)\n",
        "+            }\n",
        "+        }\n",
        "+    }\n",
        "+\n",
        "+    private _createTokenUsageTracker(): TokenUsageTracker {\n",
        "+        return {\n",
        "             promptTokens: 0,\n",
        "             completionTokens: 0,\n",
        "             totalTokens: 0\n",
        "         }\n",
        "+    }\n",
        " \n",
        "-        for await (const chunk of stream) {\n",
        "-            yield chunk\n",
        "+    private _handleStreamChunk(\n",
        "+        chunk: ChatGenerationChunk,\n",
        "+        runManager: CallbackManagerForLLMRun | undefined,\n",
        "+        latestTokenUsage: TokenUsageTracker\n",
        "+    ): boolean {\n",
        "+        const chunkText = chunk.text ?? ''\n",
        " \n",
        "-            const chunkText = chunk.text ?? ''\n",
        "+        if (chunkText) {\n",
        "+            // eslint-disable-next-line no-void\n",
        "+            void runManager?.handleLLMNewToken(chunkText)\n",
        "+        }\n",
        " \n",
        "-            if (chunkText != null) {\n",
        "-                // eslint-disable-next-line no-void\n",
        "-                void runManager?.handleLLMNewToken(chunkText)\n",
        "+        const message = chunk.message as AIMessageChunk | undefined\n",
        "+        const isToolCallMessage = this._isToolCallMessage(message)\n",
        " \n",
        "-                isToolCallMessage =\n",
        "-                    ((chunk.message as AIMessageChunk)?.tool_calls?.length ??\n",
        "-                        0) === 0 &&\n",
        "-                    ((chunk.message as AIMessageChunk)?.tool_call_chunks\n",
        "-                        ?.length ?? 0) === 0 &&\n",
        "-                    ((chunk.message as AIMessageChunk)?.invalid_tool_calls\n",
        "-                        ?.length ?? 0) === 0\n",
        "+        if (isToolCallMessage) {\n",
        "+            // eslint-disable-next-line no-void\n",
        "+            void runManager?.handleCustomEvent('LLMNewChunk', message)\n",
        "+        }\n",
        " \n",
        "-                if (isToolCallMessage) {\n",
        "-                    // eslint-disable-next-line no-void\n",
        "-                    void runManager?.handleCustomEvent(\n",
        "-                        'LLMNewChunk',\n",
        "-                        chunk.message\n",
        "-                    )\n",
        "-                }\n",
        "-            }\n",
        "+        this._updateTokenUsageFromChunk(chunk, latestTokenUsage)\n",
        " \n",
        "-            if (\n",
        "-                chunk.generationInfo != null &&\n",
        "-                chunk.generationInfo['tokenUsage'] != null\n",
        "-            ) {\n",
        "-                latestTokenUsage.promptTokens =\n",
        "-                    chunk.generationInfo['tokenUsage']['promptTokens']\n",
        "-                latestTokenUsage.completionTokens =\n",
        "-                    chunk.generationInfo['tokenUsage']['completionTokens']\n",
        "-                latestTokenUsage.totalTokens =\n",
        "-                    chunk.generationInfo['tokenUsage']['totalTokens']\n",
        "-            }\n",
        "+        return isToolCallMessage\n",
        "+    }\n",
        "+\n",
        "+    private _isToolCallMessage(message?: AIMessageChunk): boolean {\n",
        "+        return (\n",
        "+            (message?.tool_calls?.length ?? 0) === 0 &&\n",
        "+            (message?.tool_call_chunks?.length ?? 0) === 0 &&\n",
        "+            (message?.invalid_tool_calls?.length ?? 0) === 0\n",
        "+        )\n",
        "+    }\n",
        " \n",
        "-            if (!hasChunk) hasChunk = true\n",
        "+    private _updateTokenUsageFromChunk(\n",
        "+        chunk: ChatGenerationChunk,\n",
        "+        latestTokenUsage: TokenUsageTracker\n",
        "+    ) {\n",
        "+        const tokenUsage = chunk.message.response_metadata?.['tokenUsage']\n",
        "+\n",
        "+        if (!tokenUsage) {\n",
        "+            return\n",
        "         }\n",
        " \n",
        "-        if (!hasChunk) {\n",
        "-            throw new ChatLunaError(ChatLunaErrorCode.API_REQUEST_FAILED)\n",
        "+        latestTokenUsage.promptTokens = tokenUsage['promptTokens']\n",
        "+        latestTokenUsage.completionTokens = tokenUsage['completionTokens']\n",
        "+        latestTokenUsage.totalTokens = tokenUsage['totalTokens']\n",
        "+    }\n",
        "+\n",
        "+    private _ensureChunksReceived(hasChunk: boolean) {\n",
        "+        if (hasChunk) {\n",
        "+            return\n",
        "         }\n",
        " \n",
        "+        throw new ChatLunaError(ChatLunaErrorCode.API_REQUEST_FAILED)\n",
        "+    }\n",
        "+\n",
        "+    private _finalizeStream(\n",
        "+        isToolCallMessage: boolean,\n",
        "+        latestTokenUsage: TokenUsageTracker,\n",
        "+        runManager?: CallbackManagerForLLMRun\n",
        "+    ) {\n",
        "         if (isToolCallMessage) {\n",
        "             // eslint-disable-next-line no-void\n",
        "             void runManager?.handleCustomEvent('LLMNewChunk', undefined)\n",
        "         }\n",
        " \n",
        "-        if (latestTokenUsage.totalTokens > 0) {\n",
        "+        if (latestTokenUsage.totalTokens <= 0) {\n",
        "+            return\n",
        "+        }\n",
        "+\n",
        "+        logger.debug(\n",
        "+            'Token usage from API: Prompt Token = %d, Completion Token = %d, Total Token = %d',\n",
        "+            latestTokenUsage.promptTokens,\n",
        "+            latestTokenUsage.completionTokens,\n",
        "+            latestTokenUsage.totalTokens\n",
        "+        )\n",
        "+    }\n",
        "+\n",
        "+    private async _closeStream(\n",
        "+        stream: AsyncGenerator<ChatGenerationChunk> | null\n",
        "+    ) {\n",
        "+        if (stream?.return == null) {\n",
        "+            return\n",
        "+        }\n",
        "+\n",
        "+        try {\n",
        "+            await stream.return(undefined)\n",
        "+        } catch (error) {\n",
        "             logger.debug(\n",
        "-                'Token usage from API: Prompt Token = %d, Completion Token = %d, Total Token = %d',\n",
        "-                latestTokenUsage.promptTokens,\n",
        "-                latestTokenUsage.completionTokens,\n",
        "-                latestTokenUsage.totalTokens\n",
        "+                'Failed to close stream on retry: %s',\n",
        "+                (error as Error)?.message\n",
        "             )\n",
        "         }\n",
        "     }\n",
        " \n",
        "+    private _shouldRethrowStreamError(\n",
        "+        error: unknown,\n",
        "+        hasChunk: boolean,\n",
        "+        attempt: number,\n",
        "+        maxRetries: number\n",
        "+    ): boolean {\n",
        "+        return (\n",
        "+            this._isAbortError(error) || hasChunk || attempt === maxRetries - 1\n",
        "+        )\n",
        "+    }\n",
        "+\n",
        "+    private _isAbortError(error: unknown): boolean {\n",
        "+        if (error instanceof ChatLunaError) {\n",
        "+            return error.errorCode === ChatLunaErrorCode.ABORTED\n",
        "+        }\n",
        "+\n",
        "+        return (error as Error)?.name === 'AbortError'\n",
        "+    }\n",
        "+\n",
        "     async _generate(\n",
        "         messages: BaseMessage[],\n",
        "         options: this['ParsedCallOptions'],\n",
        "@@ -295,24 +393,28 @@ export class ChatLunaChatModel extends BaseChatModel<ChatLunaModelCallOptions> {\n",
        "             throw new ChatLunaError(ChatLunaErrorCode.API_REQUEST_FAILED)\n",
        "         }\n",
        " \n",
        "-        response.generationInfo = response.generationInfo ?? {}\n",
        "+        response.message.response_metadata =\n",
        "+            response.message.response_metadata ?? {}\n",
        " \n",
        "-        if (response.generationInfo.tokenUsage == null) {\n",
        "+        if (!response.message.response_metadata.tokenUsage) {\n",
        "             const completionTokens = await this.countMessageTokens(\n",
        "                 response.message\n",
        "             )\n",
        "-            response.generationInfo.tokenUsage = {\n",
        "+            response.message.response_metadata.tokenUsage = {\n",
        "                 completionTokens,\n",
        "                 promptTokens,\n",
        "                 totalTokens: completionTokens + promptTokens\n",
        "             }\n",
        "         } else if (options.stream !== true) {\n",
        "-            logger.debug(\n",
        "-                'Token usage from API: Prompt Token = %d, Completion Token = %d, Total Token = %d',\n",
        "-                response.generationInfo['tokenUsage']['promptTokens'],\n",
        "-                response.generationInfo['tokenUsage']['completionTokens'],\n",
        "-                response.generationInfo['tokenUsage']['totalTokens']\n",
        "-            )\n",
        "+            const tokenUsage = response.message.response_metadata['tokenUsage']\n",
        "+            if (tokenUsage) {\n",
        "+                logger.debug(\n",
        "+                    'Token usage from API: Prompt Token = %d, Completion Token = %d, Total Token = %d',\n",
        "+                    tokenUsage.promptTokens,\n",
        "+                    tokenUsage.completionTokens,\n",
        "+                    tokenUsage.totalTokens\n",
        "+                )\n",
        "+            }\n",
        "         }\n",
        " \n",
        "         return {\n"
      ]
    },
    {
      "path": "packages/core/src/llm-core/platform/types.ts",
      "status": "modified",
      "additions": 6,
      "deletions": 0,
      "patch": "@@ -127,3 +127,9 @@ export function isPlatformModelInfo(model: any): model is PlatformModelInfo {\n         model['platform'] !== 'default'\n     )\n }\n+\n+export type TokenUsageTracker = {\n+    promptTokens: number\n+    completionTokens: number\n+    totalTokens: number\n+}",
      "patch_lines": [
        "@@ -127,3 +127,9 @@ export function isPlatformModelInfo(model: any): model is PlatformModelInfo {\n",
        "         model['platform'] !== 'default'\n",
        "     )\n",
        " }\n",
        "+\n",
        "+export type TokenUsageTracker = {\n",
        "+    promptTokens: number\n",
        "+    completionTokens: number\n",
        "+    totalTokens: number\n",
        "+}\n"
      ]
    },
    {
      "path": "packages/extension-long-memory/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -62,7 +62,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"resolutions\": {\n         \"@langchain/core\": \"0.3.62\",",
      "patch_lines": [
        "@@ -62,7 +62,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"resolutions\": {\n",
        "         \"@langchain/core\": \"0.3.62\",\n"
      ]
    },
    {
      "path": "packages/extension-mcp/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -60,7 +60,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\",\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\",\n         \"koishi-plugin-chatluna-storage-service\": \"^0.0.11\"\n     },\n     \"peerDependenciesMeta\": {",
      "patch_lines": [
        "@@ -60,7 +60,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\",\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\",\n",
        "         \"koishi-plugin-chatluna-storage-service\": \"^0.0.11\"\n",
        "     },\n",
        "     \"peerDependenciesMeta\": {\n"
      ]
    },
    {
      "path": "packages/extension-tools/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -68,7 +68,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\",\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\",\n         \"koishi-plugin-chatluna-storage-service\": \"^0.0.11\"\n     },\n     \"peerDependenciesMeta\": {",
      "patch_lines": [
        "@@ -68,7 +68,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\",\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\",\n",
        "         \"koishi-plugin-chatluna-storage-service\": \"^0.0.11\"\n",
        "     },\n",
        "     \"peerDependenciesMeta\": {\n"
      ]
    },
    {
      "path": "packages/extension-variable/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -58,7 +58,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"resolutions\": {\n         \"@langchain/core\": \"0.3.62\",",
      "patch_lines": [
        "@@ -58,7 +58,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"resolutions\": {\n",
        "         \"@langchain/core\": \"0.3.62\",\n"
      ]
    },
    {
      "path": "packages/renderer-image/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -62,7 +62,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -62,7 +62,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/service-embeddings/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -63,7 +63,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -63,7 +63,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/service-image/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -59,7 +59,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"resolutions\": {\n         \"@langchain/core\": \"0.3.62\",",
      "patch_lines": [
        "@@ -59,7 +59,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"resolutions\": {\n",
        "         \"@langchain/core\": \"0.3.62\",\n"
      ]
    },
    {
      "path": "packages/service-search/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -74,7 +74,7 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"koishi\": {\n         \"description\": {",
      "patch_lines": [
        "@@ -74,7 +74,7 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"koishi\": {\n",
        "         \"description\": {\n"
      ]
    },
    {
      "path": "packages/service-vector-store/package.json",
      "status": "modified",
      "additions": 1,
      "deletions": 1,
      "patch": "@@ -58,7 +58,7 @@\n         \"@zilliz/milvus2-sdk-node\": \"^2.6.2\",\n         \"faiss-node\": \"^0.5.1\",\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     },\n     \"peerDependenciesMeta\": {\n         \"@zilliz/milvus2-sdk-node\": {",
      "patch_lines": [
        "@@ -58,7 +58,7 @@\n",
        "         \"@zilliz/milvus2-sdk-node\": \"^2.6.2\",\n",
        "         \"faiss-node\": \"^0.5.1\",\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     },\n",
        "     \"peerDependenciesMeta\": {\n",
        "         \"@zilliz/milvus2-sdk-node\": {\n"
      ]
    },
    {
      "path": "packages/shared-adapter/package.json",
      "status": "modified",
      "additions": 2,
      "deletions": 2,
      "patch": "@@ -1,7 +1,7 @@\n {\n     \"name\": \"@chatluna/v1-shared-adapter\",\n     \"description\": \"chatluna shared adapter\",\n-    \"version\": \"1.0.15\",\n+    \"version\": \"1.0.16\",\n     \"main\": \"lib/index.cjs\",\n     \"module\": \"lib/index.mjs\",\n     \"typings\": \"lib/index.d.ts\",\n@@ -70,6 +70,6 @@\n     },\n     \"peerDependencies\": {\n         \"koishi\": \"^4.18.9\",\n-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n     }\n }",
      "patch_lines": [
        "@@ -1,7 +1,7 @@\n",
        " {\n",
        "     \"name\": \"@chatluna/v1-shared-adapter\",\n",
        "     \"description\": \"chatluna shared adapter\",\n",
        "-    \"version\": \"1.0.15\",\n",
        "+    \"version\": \"1.0.16\",\n",
        "     \"main\": \"lib/index.cjs\",\n",
        "     \"module\": \"lib/index.mjs\",\n",
        "     \"typings\": \"lib/index.d.ts\",\n",
        "@@ -70,6 +70,6 @@\n",
        "     },\n",
        "     \"peerDependencies\": {\n",
        "         \"koishi\": \"^4.18.9\",\n",
        "-        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.76\"\n",
        "+        \"koishi-plugin-chatluna\": \"^1.3.0-alpha.77\"\n",
        "     }\n",
        " }\n"
      ]
    },
    {
      "path": "packages/shared-adapter/src/requester.ts",
      "status": "modified",
      "additions": 10,
      "deletions": 8,
      "patch": "@@ -152,15 +152,17 @@ export async function* processStreamResponse<\n \n             if (data.usage) {\n                 yield new ChatGenerationChunk({\n-                    message: new AIMessageChunk(''),\n-                    text: '',\n-                    generationInfo: {\n-                        tokenUsage: {\n-                            promptTokens: data.usage.prompt_tokens,\n-                            completionTokens: data.usage.completion_tokens,\n-                            totalTokens: data.usage.total_tokens\n+                    message: new AIMessageChunk({\n+                        content: '',\n+                        response_metadata: {\n+                            tokenUsage: {\n+                                promptTokens: data.usage.prompt_tokens,\n+                                completionTokens: data.usage.completion_tokens,\n+                                totalTokens: data.usage.total_tokens\n+                            }\n                         }\n-                    }\n+                    }),\n+                    text: ''\n                 })\n             }\n ",
      "patch_lines": [
        "@@ -152,15 +152,17 @@ export async function* processStreamResponse<\n",
        " \n",
        "             if (data.usage) {\n",
        "                 yield new ChatGenerationChunk({\n",
        "-                    message: new AIMessageChunk(''),\n",
        "-                    text: '',\n",
        "-                    generationInfo: {\n",
        "-                        tokenUsage: {\n",
        "-                            promptTokens: data.usage.prompt_tokens,\n",
        "-                            completionTokens: data.usage.completion_tokens,\n",
        "-                            totalTokens: data.usage.total_tokens\n",
        "+                    message: new AIMessageChunk({\n",
        "+                        content: '',\n",
        "+                        response_metadata: {\n",
        "+                            tokenUsage: {\n",
        "+                                promptTokens: data.usage.prompt_tokens,\n",
        "+                                completionTokens: data.usage.completion_tokens,\n",
        "+                                totalTokens: data.usage.total_tokens\n",
        "+                            }\n",
        "                         }\n",
        "-                    }\n",
        "+                    }),\n",
        "+                    text: ''\n",
        "                 })\n",
        "             }\n",
        " \n"
      ]
    }
  ]
}